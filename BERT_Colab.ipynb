{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwM0a5su8t6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35ef3e4-3eea-4044-d3cf-f575f80d6c5d"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random, pickle, os\n",
        "\n",
        "from numpy import dstack, array, mean, std\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, regularizers\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouRuH7EX83GG",
        "outputId": "67435f5b-1ce7-410c-aa73-85be57461e1e"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiKV3DBsZuEf",
        "outputId": "ab0f400e-ba5b-4f17-b0e0-a92e489d52ec"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyiMRKjOxSQt",
        "outputId": "2474ccee-06e2-4055-c5ee-382380773d2d"
      },
      "source": [
        "! pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDj_3yFL9CPu"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjBpBm9RPWyM"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import unicodedata\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.layers import Dense,Dropout, Input\r\n",
        "from tqdm import tqdm\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import itertools\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from transformers import *\r\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5UyrvdraVx5"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-o5-BNZaV05"
      },
      "source": [
        "def unicode_to_ascii(s):\r\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\r\n",
        "\r\n",
        "def clean_stopwords_shortwords(w):\r\n",
        "    stopwords_list=stopwords.words('english')\r\n",
        "    words = w.split() \r\n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\r\n",
        "    return \" \".join(clean_words) \r\n",
        "\r\n",
        "def preprocess_sentence(w):\r\n",
        "    w = unicode_to_ascii(w.lower().strip())\r\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\r\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\r\n",
        "    w=clean_stopwords_shortwords(w)\r\n",
        "    w=re.sub(r'@\\w+', '',w)\r\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml5mKPqub3yx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d2e247a4-e870-481d-e887-684b986a741a"
      },
      "source": [
        "data_file='./train_data_tagging_wo_duration.csv'\r\n",
        "data=pd.read_csv(data_file,encoding='ISO-8859-1')\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_content</th>\n",
              "      <th>file_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trans.2023.txt</td>\n",
              "      <td>Agent [silence] Customer all right Agent okay ...</td>\n",
              "      <td>Credit Card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trans.2061.txt</td>\n",
              "      <td>Agent [noise] Customer [noise] Agent [silence]...</td>\n",
              "      <td>Credit Card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trans.2067.txt</td>\n",
              "      <td>Agent [noise] Customer [noise] Agent well um w...</td>\n",
              "      <td>Credit Card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trans.2163.txt</td>\n",
              "      <td>Agent [silence] Customer okay i was trying to ...</td>\n",
              "      <td>Credit Card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trans.2313.txt</td>\n",
              "      <td>Agent [noise] Customer [silence] Agent [silenc...</td>\n",
              "      <td>Credit Card</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        file_name  ...     file_tag\n",
              "0  trans.2023.txt  ...  Credit Card\n",
              "1  trans.2061.txt  ...  Credit Card\n",
              "2  trans.2067.txt  ...  Credit Card\n",
              "3  trans.2163.txt  ...  Credit Card\n",
              "4  trans.2313.txt  ...  Credit Card\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOj6bK86Szez",
        "outputId": "d3e213dc-e4c9-4f4e-92f7-d69f78c314d2"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o33KRcISnhK"
      },
      "source": [
        "data['file_content']=data['file_content'].map(preprocess_sentence)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j42Q9Rcu13k"
      },
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//150 >0:\n",
        "        n = len(text1.split())//150\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIn9I11Ou-Xe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3l_ILlqIu-al",
        "outputId": "b9227c72-7bef-4bc5-923e-b07fea74c9cc"
      },
      "source": [
        "data['file_content_split'] = data['file_content'].apply(get_split)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_content</th>\n",
              "      <th>file_tag</th>\n",
              "      <th>file_content_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trans.2023.txt</td>\n",
              "      <td>agent silence customer right agent okay custom...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent silence customer right agent okay custo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trans.2061.txt</td>\n",
              "      <td>agent noise customer noise agent silence custo...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent noise customer noise agent silence cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trans.2067.txt</td>\n",
              "      <td>agent noise customer noise agent well credit c...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent noise customer noise agent well credit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trans.2163.txt</td>\n",
              "      <td>agent silence customer okay trying get childre...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent silence customer okay trying get childr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trans.2313.txt</td>\n",
              "      <td>agent noise customer silence agent silence cus...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent noise customer silence agent silence cu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        file_name  ...                                 file_content_split\n",
              "0  trans.2023.txt  ...  [agent silence customer right agent okay custo...\n",
              "1  trans.2061.txt  ...  [agent noise customer noise agent silence cust...\n",
              "2  trans.2067.txt  ...  [agent noise customer noise agent well credit ...\n",
              "3  trans.2163.txt  ...  [agent silence customer okay trying get childr...\n",
              "4  trans.2313.txt  ...  [agent noise customer silence agent silence cu...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Mk2rXDvXjC"
      },
      "source": [
        "data['file_content_split'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930RP1nmS5fk"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdIue454v-Qr",
        "outputId": "beb92932-c876-40a0-ac15-dbceb5daebf2"
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = './bert_conersation_tagging'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "    try:\n",
        "        os.rmdir(OUTPUT_DIR)\n",
        "#         tf.compat.v1.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "os.mkdir(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: ./bert_conersation_tagging *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gT_2-Xvv-Th",
        "outputId": "f1fbf456-0a98-49ae-9525-68c7c4f50296"
      },
      "source": [
        "# Get labels\n",
        "label_list = [x for x in np.unique(data.file_tag)]\n",
        "label_list\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bank Bailout',\n",
              " 'Budget',\n",
              " 'Credit Card',\n",
              " 'Family Finance',\n",
              " 'Job Benefits',\n",
              " 'Taxes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pLRz2Xhfa84n",
        "outputId": "ab3d3f56-d4a6-423f-bd50-60b121c371e1"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb_make = LabelEncoder()\n",
        "data[\"file_tag_encoder\"] = lb_make.fit_transform(data.file_tag.astype(str))\n",
        "data[[\"file_tag\", \"file_tag_encoder\"]].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_tag</th>\n",
              "      <th>file_tag_encoder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Credit Card</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Credit Card</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Credit Card</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Credit Card</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Credit Card</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      file_tag  file_tag_encoder\n",
              "0  Credit Card                 2\n",
              "1  Credit Card                 2\n",
              "2  Credit Card                 2\n",
              "3  Credit Card                 2\n",
              "4  Credit Card                 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "XpwC0WoXv-We",
        "outputId": "ad940232-20a9-4713-93bf-e49937e90eaf"
      },
      "source": [
        "train, val = train_test_split(data, test_size=0.2, random_state=35,stratify=data['file_tag_encoder'])\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "train.head(2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_content</th>\n",
              "      <th>file_tag</th>\n",
              "      <th>file_content_split</th>\n",
              "      <th>file_tag_encoder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trans.4161.txt</td>\n",
              "      <td>agent noise customer noise customer keep budge...</td>\n",
              "      <td>Family Finance</td>\n",
              "      <td>[agent noise customer noise customer keep budg...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trans.2951.txt</td>\n",
              "      <td>agent silence customer noise customer okay cus...</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>[agent silence customer noise customer okay cu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        file_name  ... file_tag_encoder\n",
              "0  trans.4161.txt  ...                3\n",
              "1  trans.2951.txt  ...                2\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN7OqLcMv-Zf",
        "outputId": "84104b31-e59d-4a0e-f752-c044e6c3807a"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKK_-hhAywW_"
      },
      "source": [
        "val, test = train_test_split(val, test_size=0.2, random_state=35)\n",
        "val.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_reAYabDyjBV",
        "outputId": "fa5fd52a-028b-4e27-ea79-e2e30de790d7"
      },
      "source": [
        "val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIqQyGUUyjEG",
        "outputId": "29c8df4e-cf53-43c9-9d83-2a42f603cc6f"
      },
      "source": [
        "train_l = []\n",
        "label_l = []\n",
        "index_l =[]\n",
        "for idx,row in train.iterrows():\n",
        "    for l in row['file_content_split']:\n",
        "        train_l.append(l)\n",
        "        label_l.append(row['file_tag_encoder'])\n",
        "        index_l.append(idx)\n",
        "len(train_l), len(label_l), len(index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(856, 856, 856)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_sG0ZkWyjJk",
        "outputId": "369d9dd9-e51f-440d-829a-1c722c449c64"
      },
      "source": [
        "label_l[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8yDb51_yjMd",
        "outputId": "79c65f6e-1f4e-4257-e12d-36061b3c7115"
      },
      "source": [
        "val_l = []\n",
        "val_label_l = []\n",
        "val_index_l = []\n",
        "for idx,row in val.iterrows():\n",
        "    for l in row['file_content_split']:\n",
        "        val_l.append(l)\n",
        "        val_label_l.append(row['file_tag_encoder'])\n",
        "        val_index_l.append(idx)\n",
        "len(val_l), len(val_label_l), len(val_index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(173, 173, 173)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o151xUC0I_x",
        "outputId": "427e9f6d-66d9-42ef-c394-d70c5528c599"
      },
      "source": [
        "test_l = []\n",
        "test_label_l = []\n",
        "test_index_l = []\n",
        "for idx,row in test.iterrows():\n",
        "    for l in row['file_content_split']:\n",
        "        test_l.append(l)\n",
        "        test_label_l.append(row['file_tag_encoder'])\n",
        "        test_index_l.append(idx)\n",
        "len(test_l), len(test_label_l), len(test_index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 45, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3cJhwZJ0JCy",
        "outputId": "9f2ecec6-3726-42f8-d5fe-0666c4d7e43d"
      },
      "source": [
        "test['file_content_split'][73]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['agent noise customer noise customer ahead tell think get money worth agent silence agent hey listen way pay taxes things hear tax money going ludicrous things customer silence customer yeah see sixty minutes last night agent customer well noise thing thirty five billion dollars waste every year storing stuff military need agent silence agent well grab grab customer staggering customer silence agent mean lady heard christian program agent nea national endowment arts fund agent funded thing act stage study two lesbians two homosexuals wrote report money customer well lot things people think generally agent silence agent frosts terribly customer silence customer well think interesting look agent silence customer money vocalized noise goes goes lot places probably ought think generally think interesting agent absolutely agent silence customer noise probably represent majority people country terms feelings government serves given extraordinarily large sum money government operate agent believe true yes customer think gonna really interesting mean gonna change people represent agent silence agent correct customer mean think gonna real interesting see force upon agent silence agent heavy involvement public customer yeah right think thing gonna change agent hum agent yeah heavy involvement public customer anger gonna give rise activity part agent yeah agent',\n",
              " 'really interesting mean gonna change people represent agent silence agent correct customer mean think gonna real interesting see force upon agent silence agent heavy involvement public customer yeah right think thing gonna change agent hum agent yeah heavy involvement public customer anger gonna give rise activity part agent yeah agent silence customer said years full employment politically active society little full employment people country getting worse better agent absolutely customer eighty percent public according bill moyer recent piece public broadcasting agent silence customer noise way good use government money think pbs wonderful special customer focused fact eighty percent people country seeing real incomes thus standards living decline twenty percent seeing improve customer formula better society agent lopsided much customer silence customer government really plays role agent silence agent huh right pull strings customer silence customer mean vocalized noise ell well people whose strings pulled guess powerful inter est agent silence agent right yeah laughter customer silence customer know really interesting see affects people essentially people country agent silence customer likely revolt way people used think voter revolting customer people pretty much getting picture people get taken care others think unfair recognize tax money gonna customer ink tell one quick one',\n",
              " 'agent right yeah laughter customer silence customer know really interesting see affects people essentially people country agent silence customer likely revolt way people used think voter revolting customer people pretty much getting picture people get taken care others think unfair recognize tax money gonna customer ink tell one quick one thing interesting cbs state union address gonna open telephone line customer eight hundred number people call say think going country expect agent hum agent silence customer noise opening one hour get three hundred thousand telephone calls agent sure customer thought years would make lot sense create eight hundred number voters call vent frustration government agent silence agent hum customer like one eight hundred capitol something like know number could call anywhere anytime think coming think people really start communicate feel things going change agent silence agent huh agent silence customer think know gonna really painful question soon gonna start get money worth said soon get involved think need create mechanisms allow get involved like allowing call toll free number say hey look customer way way like like feel spending money art think art agent yes understand hopefully people listening comments take action customer silence customer noise well good thing happening']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "rBjrCM_y0JFU",
        "outputId": "995c714b-dc4e-48e0-ef3a-da9cfbee8a14"
      },
      "source": [
        "test_l[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'agent right yeah laughter customer silence customer know really interesting see affects people essentially people country agent silence customer likely revolt way people used think voter revolting customer people pretty much getting picture people get taken care others think unfair recognize tax money gonna customer ink tell one quick one thing interesting cbs state union address gonna open telephone line customer eight hundred number people call say think going country expect agent hum agent silence customer noise opening one hour get three hundred thousand telephone calls agent sure customer thought years would make lot sense create eight hundred number voters call vent frustration government agent silence agent hum customer like one eight hundred capitol something like know number could call anywhere anytime think coming think people really start communicate feel things going change agent silence agent huh agent silence customer think know gonna really painful question soon gonna start get money worth said soon get involved think need create mechanisms allow get involved like allowing call toll free number say hey look customer way way like like feel spending money art think art agent yes understand hopefully people listening comments take action customer silence customer noise well good thing happening'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cLXWGBmW0JIg",
        "outputId": "dee1a34a-4827-4ae9-efaa-4f3798581e0f"
      },
      "source": [
        "train_df = pd.DataFrame({\"text\":train_l, 'label':label_l})\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>agent noise customer noise customer keep budge...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>much discussion customer real conflict whether...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good think ever agent one financial crisis kno...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>agent silence customer noise customer okay cus...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>right really show lot restraint look noise loo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  agent noise customer noise customer keep budge...      3\n",
              "1  much discussion customer real conflict whether...      3\n",
              "2  good think ever agent one financial crisis kno...      3\n",
              "3  agent silence customer noise customer okay cus...      2\n",
              "4  right really show lot restraint look noise loo...      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PauObw7NyjPU",
        "outputId": "ade45d34-8048-4457-e356-716c8eaa29df"
      },
      "source": [
        "val_df = pd.DataFrame({\"text\":val_l, 'label':val_label_l})\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>agent noise customer noise well view work fina...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like discover huh well tell works use discover...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>agent yeah either gone although debit end mont...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>agent noise customer noise agent vocalized noi...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>right customer silence agent silence agent wel...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  agent noise customer noise well view work fina...      2\n",
              "1  like discover huh well tell works use discover...      2\n",
              "2  agent yeah either gone although debit end mont...      2\n",
              "3  agent noise customer noise agent vocalized noi...      3\n",
              "4  right customer silence agent silence agent wel...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unThWQ8p3mKY",
        "outputId": "ad6e375e-dde0-4d53-ea98-ebd8745ebb91"
      },
      "source": [
        "val_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(173, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6Yaa0MTj6Ab7",
        "outputId": "92c1cd8e-3c6d-4089-dfed-b6953699b3e0"
      },
      "source": [
        "test_df = pd.DataFrame({\"text\":test_l, 'label':test_label_l})\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>agent noise customer noise customer ahead tell...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>really interesting mean gonna change people re...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>agent right yeah laughter customer silence cus...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>agent noise customer silence customer yes agen...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>social security tax principle going big trust ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  agent noise customer noise customer ahead tell...      5\n",
              "1  really interesting mean gonna change people re...      5\n",
              "2  agent right yeah laughter customer silence cus...      5\n",
              "3  agent noise customer silence customer yes agen...      5\n",
              "4  social security tax principle going big trust ...      5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSyQBNxN9tvz"
      },
      "source": [
        "DATA_COLUMN='file_content'\n",
        "LABEL_COLUMN='file_tag'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woczCSOA_n9-"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py\n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py\n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ha4j8-_44A"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXERhvDcAQH-"
      },
      "source": [
        "# BERT\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muDzBoZPGqIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKT4cuXEGe-C"
      },
      "source": [
        "from run_classifier import InputExample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHfZBasl-axR"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import re, os\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXQ5o14K6Aet"
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwiFvBp88_nM",
        "outputId": "36680b75-9d5b-4cc2-d073-04c7cd0366c4"
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      <run_classifier.InputExample object at 0x7fa71...\n",
              "1      <run_classifier.InputExample object at 0x7fa71...\n",
              "2      <run_classifier.InputExample object at 0x7fa71...\n",
              "3      <run_classifier.InputExample object at 0x7fa71...\n",
              "4      <run_classifier.InputExample object at 0x7fa71...\n",
              "                             ...                        \n",
              "187    <run_classifier.InputExample object at 0x7fa71...\n",
              "188    <run_classifier.InputExample object at 0x7fa71...\n",
              "189    <run_classifier.InputExample object at 0x7fa71...\n",
              "190    <run_classifier.InputExample object at 0x7fa71...\n",
              "191    <run_classifier.InputExample object at 0x7fa71...\n",
              "Length: 192, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KAk1xov8_qI",
        "outputId": "358d8a75-e597-4d10-dbf9-44f8b8573be9"
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track pennies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked budget going spend agent laughter agent good tried beginning hen hen say tried tried sit consensus customer silence customer agent agreed noise customer silence agent shall say best consensus could get pretty thrifty noise agent know watch spend money big items noise kind talk two agent noise playing russian roulette guess although married agent many years agent noise agent let see customer laughter agent twenty six twenty seven years customer silence customer ound sounds like guys gotten something worked gonna work fine agent silence agent well kind commitment spend much customer silence customer yeah agent noise customer silence agent budget idea sounds pretty good think ever agent one financial crisis know like agent emergency kind job loss something like noise neither one noise agent predict ing two bank accounts customer hum agent one wanted customer silence agent silence agent wanted learn balance checkbook agent agent noise best keep current speak gave another checkbook said okay account money anytime customer yeah customer silence agent want tell much account customer hum agent laughter said trying control said know six hundred dollars want another three hundred tell customer silence agent finally got one things get money agent company puts makes direct deposit customer yes agent noise give customer silence agent let see noise gets like third money household pay everything else agent silence customer yeah done see married three years customer wife real good checkbooks math stuff gave said everything customer come help agent think good customer silence customer really good know come appreciate understand going everything really quite nice actually laughter agent silence customer agent think good one friends suggested customer silence agent life would little easier around house even yet\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Dh-kcRUscEsK",
        "outputId": "81eb3172-c8c2-4634-b59a-1fd157190865"
      },
      "source": [
        "train_InputExamples.iloc[0].text_a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track pennies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked budget going spend agent laughter agent good tried beginning hen hen say tried tried sit consensus customer silence customer agent agreed noise customer silence agent shall say best consensus could get pretty thrifty noise agent know watch spend money big items noise kind talk two agent noise playing russian roulette guess although married agent many years agent noise agent let see customer laughter agent twenty six twenty seven years customer silence customer ound sounds like guys gotten something worked gonna work fine agent silence agent well kind commitment spend much customer silence customer yeah agent noise customer silence agent budget idea sounds pretty good think ever agent one financial crisis know like agent emergency kind job loss something like noise neither one noise agent predict ing two bank accounts customer hum agent one wanted customer silence agent silence agent wanted learn balance checkbook agent agent noise best keep current speak gave another checkbook said okay account money anytime customer yeah customer silence agent want tell much account customer hum agent laughter said trying control said know six hundred dollars want another three hundred tell customer silence agent finally got one things get money agent company puts makes direct deposit customer yes agent noise give customer silence agent let see noise gets like third money household pay everything else agent silence customer yeah done see married three years customer wife real good checkbooks math stuff gave said everything customer come help agent think good customer silence customer really good know come appreciate understand going everything really quite nice actually laughter agent silence customer agent think good one friends suggested customer silence agent life would little easier around house even yet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "UNQWl5qN8_s_",
        "outputId": "4b03e2d8-e076-4a24-b2d1-f9f248594bfa"
      },
      "source": [
        "train['file_content'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track pennies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked budget going spend agent laughter agent good tried beginning hen hen say tried tried sit consensus customer silence customer agent agreed noise customer silence agent shall say best consensus could get pretty thrifty noise agent know watch spend money big items noise kind talk two agent noise playing russian roulette guess although married agent many years agent noise agent let see customer laughter agent twenty six twenty seven years customer silence customer ound sounds like guys gotten something worked gonna work fine agent silence agent well kind commitment spend much customer silence customer yeah agent noise customer silence agent budget idea sounds pretty good think ever agent one financial crisis know like agent emergency kind job loss something like noise neither one noise agent predict ing two bank accounts customer hum agent one wanted customer silence agent silence agent wanted learn balance checkbook agent agent noise best keep current speak gave another checkbook said okay account money anytime customer yeah customer silence agent want tell much account customer hum agent laughter said trying control said know six hundred dollars want another three hundred tell customer silence agent finally got one things get money agent company puts makes direct deposit customer yes agent noise give customer silence agent let see noise gets like third money household pay everything else agent silence customer yeah done see married three years customer wife real good checkbooks math stuff gave said everything customer come help agent think good customer silence customer really good know come appreciate understand going everything really quite nice actually laughter agent silence customer agent think good one friends suggested customer silence agent life would little easier around house even yet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqMGkIIf6AiY",
        "outputId": "a9fca3e2-57d7-490f-8956-bda988de5011"
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "#     with tf.compat.v1.Session() as sess:\n",
        "        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "    return tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh3gCnbW6AmP",
        "outputId": "d00f141a-01f3-48bd-f28e-811811a0d2cb"
      },
      "source": [
        "len(tokenizer.vocab.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2mMokbsRMd2",
        "outputId": "21f86b3a-9061-4735-ed40-fad4c4847b27"
      },
      "source": [
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['agent', 'noise', 'customer', 'noise', 'customer', 'keep', 'budget', 'agent', 'silence', 'agent', 'noise', 'really', 'one', 'commitment', 'end', 'month', 'customer', 'silence', 'agent', 'everything', 'paid', 'agent', 'basically', 'budget', 'customer', 'budget', 'agent', 'use', 'credit', 'cards', 'let', 'see', 'else', 'get', 'customer', 'silence', 'agent', 'get', 'bill', 'mail', 'write', 'check', 'immediately', 'customer', 'yep', 'agent', 'put', 'date', 'outside', 'envelope', 'stick', 'little', 'franklin', 'planner', 'customer', 'silence', 'agent', 'agent', 'carry', 'around', 'day', 'supposed', 'mail', 'mail', 'way', 'know', 'much', 'hole', 'agent', 'basically', 'noise', 'budget', 'based', 'agent', 'noise', 'agent', 'noise', 'bank', 'account', 'low', 'spend', 'much', 'customer', 'yeah', 'agent', 'silence', 'customer', 'noise', 'customer', 'wife', 'customer', 'new', 'young', 'couple', 'starting', 'trying', 'noise', 'budget', 'getting', 'lot', 'customer', 'lot', 'tighter', 'actually', 'worked', 'extensive', 'year', 'long', 'budget', 'agent', 'wow', 'customer', 'know', 'exactly', 'gonna', 'spend', 'gonna', 'money', 'worked', 'cash', 'flow', 'agent', 'silence', 'customer', 'bought', 'house', 'another', 'reason', 'really', 'keeping', 'track', 'penn', '##ies', 'stuff', 'agent', 'yeah', 'agent', 'laughter', 'customer', 'laughter', 'agent', 'silence', 'customer', 'detailed', 'budget', 'ways', 'really', 'kind', 'nice', 'much', 'worry', 'much', 'discussion', 'customer', 'real', 'conflict', 'whether', 'always', 'sense', 'confidence', 'little', 'bit', 'know', 'going', 'money', 'said', 'going', 'agent', 'yeah', 'agent', 'silence', 'agent', 'consensus', 'customer', 'silence', 'customer', 'yeah', 'brother', 'told', 'accounting', 'suggested', 'agent', 'ahead', 'time', 'huh', 'agent', 'silence', 'customer', 'making', 'big', 'financial', 'steps', 'stuff', 'said', 'well', 'fight', 'year', 'worked', 'budget', 'going', 'spend', 'agent', 'laughter', 'agent', 'good', 'tried', 'beginning', 'hen', 'hen', 'say', 'tried', 'tried', 'sit', 'consensus', 'customer', 'silence', 'customer', 'agent', 'agreed', 'noise', 'customer', 'silence', 'agent', 'shall', 'say', 'best', 'consensus', 'could', 'get', 'pretty', 'th', '##rift', '##y', 'noise', 'agent', 'know', 'watch', 'spend', 'money', 'big', 'items', 'noise', 'kind', 'talk', 'two', 'agent', 'noise', 'playing', 'russian', 'ro', '##ule', '##tte', 'guess', 'although', 'married', 'agent', 'many', 'years', 'agent', 'noise', 'agent', 'let', 'see', 'customer', 'laughter', 'agent', 'twenty', 'six', 'twenty', 'seven', 'years', 'customer', 'silence', 'customer', 'ou', '##nd', 'sounds', 'like', 'guys', 'gotten', 'something', 'worked', 'gonna', 'work', 'fine', 'agent', 'silence', 'agent', 'well', 'kind', 'commitment', 'spend', 'much', 'customer', 'silence', 'customer', 'yeah', 'agent', 'noise', 'customer', 'silence', 'agent', 'budget', 'idea', 'sounds', 'pretty', 'good', 'think', 'ever', 'agent', 'one', 'financial', 'crisis', 'know', 'like', 'agent', 'emergency', 'kind', 'job', 'loss', 'something', 'like', 'noise', 'neither', 'one', 'noise', 'agent', 'predict', 'ing', 'two', 'bank', 'accounts', 'customer', 'hum', 'agent', 'one', 'wanted', 'customer', 'silence', 'agent', 'silence', 'agent', 'wanted', 'learn', 'balance', 'check', '##book', 'agent', 'agent', 'noise', 'best', 'keep', 'current', 'speak', 'gave', 'another', 'check', '##book', 'said', 'okay', 'account', 'money', 'anytime', 'customer', 'yeah', 'customer', 'silence', 'agent', 'want', 'tell', 'much', 'account', 'customer', 'hum', 'agent', 'laughter', 'said', 'trying', 'control', 'said', 'know', 'six', 'hundred', 'dollars', 'want', 'another', 'three', 'hundred', 'tell', 'customer', 'silence', 'agent', 'finally', 'got', 'one', 'things', 'get', 'money', 'agent', 'company', 'puts', 'makes', 'direct', 'deposit', 'customer', 'yes', 'agent', 'noise', 'give', 'customer', 'silence', 'agent', 'let', 'see', 'noise', 'gets', 'like', 'third', 'money', 'household', 'pay', 'everything', 'else', 'agent', 'silence', 'customer', 'yeah', 'done', 'see', 'married', 'three', 'years', 'customer', 'wife', 'real', 'good', 'check', '##books', 'math', 'stuff', 'gave', 'said', 'everything', 'customer', 'come', 'help', 'agent', 'think', 'good', 'customer', 'silence', 'customer', 'really', 'good', 'know', 'come', 'appreciate', 'understand', 'going', 'everything', 'really', 'quite', 'nice', 'actually', 'laughter', 'agent', 'silence', 'customer', 'agent', 'think', 'good', 'one', 'friends', 'suggested', 'customer', 'silence', 'agent', 'life', 'would', 'little', 'easier', 'around', 'house', 'even', 'yet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0Tvy2Bsftek",
        "outputId": "e448ef8b-d9d5-47d6-9382-c7b8660dd465"
      },
      "source": [
        "MAX_SEQ_LENGTH = 200\n",
        "\n",
        "train_features = run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 192\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track penn ##ies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track penn ##ies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 8013 2562 5166 4005 4223 4005 5005 2428 2028 8426 2203 3204 8013 4223 4005 2673 3825 4005 10468 5166 8013 5166 4005 2224 4923 5329 2292 2156 2842 2131 8013 4223 4005 2131 3021 5653 4339 4638 3202 8013 15624 4005 2404 3058 2648 11255 6293 2210 5951 24555 8013 4223 4005 4005 4287 2105 2154 4011 5653 5653 2126 2113 2172 4920 4005 10468 5005 5166 2241 4005 5005 4005 5005 2924 4070 2659 5247 2172 8013 3398 4005 4223 8013 5005 8013 2564 8013 2047 2402 3232 3225 2667 5005 5166 2893 2843 8013 2843 12347 2941 2499 4866 2095 2146 5166 4005 10166 8013 2113 3599 6069 5247 6069 2769 2499 5356 4834 4005 4223 8013 4149 2160 2178 3114 2428 4363 2650 9502 3111 4933 4005 3398 4005 7239 8013 7239 4005 4223 8013 6851 5166 3971 2428 2785 3835 2172 4737 2172 6594 8013 2613 4736 3251 2467 3168 7023 2210 2978 2113 2183 2769 2056 2183 4005 3398 4005 4223 4005 10465 8013 4223 8013 3398 2567 2409 9529 4081 4005 3805 2051 9616 4005 4223 8013 2437 2502 3361 4084 4933 2056 2092 2954 2095 2499 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 8013 2562 5166 4005 4223 4005 5005 2428 2028 8426 2203 3204 8013 4223 4005 2673 3825 4005 10468 5166 8013 5166 4005 2224 4923 5329 2292 2156 2842 2131 8013 4223 4005 2131 3021 5653 4339 4638 3202 8013 15624 4005 2404 3058 2648 11255 6293 2210 5951 24555 8013 4223 4005 4005 4287 2105 2154 4011 5653 5653 2126 2113 2172 4920 4005 10468 5005 5166 2241 4005 5005 4005 5005 2924 4070 2659 5247 2172 8013 3398 4005 4223 8013 5005 8013 2564 8013 2047 2402 3232 3225 2667 5005 5166 2893 2843 8013 2843 12347 2941 2499 4866 2095 2146 5166 4005 10166 8013 2113 3599 6069 5247 6069 2769 2499 5356 4834 4005 4223 8013 4149 2160 2178 3114 2428 4363 2650 9502 3111 4933 4005 3398 4005 7239 8013 7239 4005 4223 8013 6851 5166 3971 2428 2785 3835 2172 4737 2172 6594 8013 2613 4736 3251 2467 3168 7023 2210 2978 2113 2183 2769 2056 2183 4005 3398 4005 4223 4005 10465 8013 4223 8013 3398 2567 2409 9529 4081 4005 3805 2051 9616 4005 4223 8013 2437 2502 3361 4084 4933 2056 2092 2954 2095 2499 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer noise customer okay customer want start customer agent well credit cards ink think wonderful customer silence agent think lot restraint agent silence agent never trouble credit cards youngest daughter friend mine think terrible agent know wipe max short time customer hum agent silence customer silence agent never pay interest charges value money much line somebody else pockets money customer hum customer silence agent always pay charged interest balance customer never let run agent silence agent never customer wonderful wonderful kind agent laughter agent silence customer ve ##r know depends everything paid start wanting something really enough well enough savings av ##ings know like big purchase agent hum customer sometimes lose sight know easy use agent silence customer like hate paying people interest agent hum agent silence customer make added like wrote addition car loan credit union knew lower interest pay swore would never use agent hum agent silence agent right really show lot restraint look noise look time frame find six seven weeks customer silence customer hum customer silence agent make payment back credit card company without charged interest agent silence customer thing make sure charge know going able pay agent correct yeah customer given [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer noise customer okay customer want start customer agent well credit cards ink think wonderful customer silence agent think lot restraint agent silence agent never trouble credit cards youngest daughter friend mine think terrible agent know wipe max short time customer hum agent silence customer silence agent never pay interest charges value money much line somebody else pockets money customer hum customer silence agent always pay charged interest balance customer never let run agent silence agent never customer wonderful wonderful kind agent laughter agent silence customer ve ##r know depends everything paid start wanting something really enough well enough savings av ##ings know like big purchase agent hum customer sometimes lose sight know easy use agent silence customer like hate paying people interest agent hum agent silence customer make added like wrote addition car loan credit union knew lower interest pay swore would never use agent hum agent silence agent right really show lot restraint look noise look time frame find six seven weeks customer silence customer hum customer silence agent make payment back credit card company without charged interest agent silence customer thing make sure charge know going able pay agent correct yeah customer given [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 5005 8013 3100 8013 2215 2707 8013 4005 2092 4923 5329 10710 2228 6919 8013 4223 4005 2228 2843 19355 4005 4223 4005 2196 4390 4923 5329 6587 2684 2767 3067 2228 6659 4005 2113 13387 4098 2460 2051 8013 14910 4005 4223 8013 4223 4005 2196 3477 3037 5571 3643 2769 2172 2240 8307 2842 10306 2769 8013 14910 8013 4223 4005 2467 3477 5338 3037 5703 8013 2196 2292 2448 4005 4223 4005 2196 8013 6919 6919 2785 4005 7239 4005 4223 8013 2310 2099 2113 9041 2673 3825 2707 5782 2242 2428 2438 2092 2438 10995 20704 8613 2113 2066 2502 5309 4005 14910 8013 2823 4558 4356 2113 3733 2224 4005 4223 8013 2066 5223 7079 2111 3037 4005 14910 4005 4223 8013 2191 2794 2066 2626 2804 2482 5414 4923 2586 2354 2896 3037 3477 12860 2052 2196 2224 4005 14910 4005 4223 4005 2157 2428 2265 2843 19355 2298 5005 2298 2051 4853 2424 2416 2698 3134 8013 4223 8013 14910 8013 4223 4005 2191 7909 2067 4923 4003 2194 2302 5338 3037 4005 4223 8013 2518 2191 2469 3715 2113 2183 2583 3477 4005 6149 3398 8013 2445 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 5005 8013 3100 8013 2215 2707 8013 4005 2092 4923 5329 10710 2228 6919 8013 4223 4005 2228 2843 19355 4005 4223 4005 2196 4390 4923 5329 6587 2684 2767 3067 2228 6659 4005 2113 13387 4098 2460 2051 8013 14910 4005 4223 8013 4223 4005 2196 3477 3037 5571 3643 2769 2172 2240 8307 2842 10306 2769 8013 14910 8013 4223 4005 2467 3477 5338 3037 5703 8013 2196 2292 2448 4005 4223 4005 2196 8013 6919 6919 2785 4005 7239 4005 4223 8013 2310 2099 2113 9041 2673 3825 2707 5782 2242 2428 2438 2092 2438 10995 20704 8613 2113 2066 2502 5309 4005 14910 8013 2823 4558 4356 2113 3733 2224 4005 4223 8013 2066 5223 7079 2111 3037 4005 14910 4005 4223 8013 2191 2794 2066 2626 2804 2482 5414 4923 2586 2354 2896 3037 3477 12860 2052 2196 2224 4005 14910 4005 4223 4005 2157 2428 2265 2843 19355 2298 5005 2298 2051 4853 2424 2416 2698 3134 8013 4223 8013 14910 8013 4223 4005 2191 7909 2067 4923 4003 2194 2302 5338 3037 4005 4223 8013 2518 2191 2469 3715 2113 2183 2583 3477 4005 6149 3398 8013 2445 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise family keep budget agent well sort mean mind laughter laughter write anything anything like customer silence customer yeah customer silence customer noise agent know bills customer silence agent much need extra nurse kind figure taking home hundred dollars day customer customer huh customer silence customer really agent look things like buy anything think days customer silence customer huh agent hear something three hundred dollars think three extra days know something laughter like laughter laughter everything mind days extent laughter budget yeah customer customer silence customer three extra days yeah customer silence customer huh yeah trying save house really trying penny pinch agent silence agent good one customer tell gets tough know tried write something computer stuff seems like every week something comes makes impossible agent silence agent well happens exactly happens customer silence customer car breaks somebody gets sick laughter agent hum hum think might get little ahead right happens customer silence customer exactly agent kind hard customer customer able plan save anything healthy future laughter know day day thing agent silence agent laughter agent barely get laughter customer yeah know wife daughter agent silence customer impossible agent yeah hard real hard get much [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise family keep budget agent well sort mean mind laughter laughter write anything anything like customer silence customer yeah customer silence customer noise agent know bills customer silence agent much need extra nurse kind figure taking home hundred dollars day customer customer huh customer silence customer really agent look things like buy anything think days customer silence customer huh agent hear something three hundred dollars think three extra days know something laughter like laughter laughter everything mind days extent laughter budget yeah customer customer silence customer three extra days yeah customer silence customer huh yeah trying save house really trying penny pinch agent silence agent good one customer tell gets tough know tried write something computer stuff seems like every week something comes makes impossible agent silence agent well happens exactly happens customer silence customer car breaks somebody gets sick laughter agent hum hum think might get little ahead right happens customer silence customer exactly agent kind hard customer customer able plan save anything healthy future laughter know day day thing agent silence agent laughter agent barely get laughter customer yeah know wife daughter agent silence customer impossible agent yeah hard real hard get much [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 2155 2562 5166 4005 2092 4066 2812 2568 7239 7239 4339 2505 2505 2066 8013 4223 8013 3398 8013 4223 8013 5005 4005 2113 8236 8013 4223 4005 2172 2342 4469 6821 2785 3275 2635 2188 3634 6363 2154 8013 8013 9616 8013 4223 8013 2428 4005 2298 2477 2066 4965 2505 2228 2420 8013 4223 8013 9616 4005 2963 2242 2093 3634 6363 2228 2093 4469 2420 2113 2242 7239 2066 7239 7239 2673 2568 2420 6698 7239 5166 3398 8013 8013 4223 8013 2093 4469 2420 3398 8013 4223 8013 9616 3398 2667 3828 2160 2428 2667 10647 18392 4005 4223 4005 2204 2028 8013 2425 4152 7823 2113 2699 4339 2242 3274 4933 3849 2066 2296 2733 2242 3310 3084 5263 4005 4223 4005 2092 6433 3599 6433 8013 4223 8013 2482 7807 8307 4152 5305 7239 4005 14910 14910 2228 2453 2131 2210 3805 2157 6433 8013 4223 8013 3599 4005 2785 2524 8013 8013 2583 2933 3828 2505 7965 2925 7239 2113 2154 2154 2518 4005 4223 4005 7239 4005 4510 2131 7239 8013 3398 2113 2564 2684 4005 4223 8013 5263 4005 3398 2524 2613 2524 2131 2172 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 2155 2562 5166 4005 2092 4066 2812 2568 7239 7239 4339 2505 2505 2066 8013 4223 8013 3398 8013 4223 8013 5005 4005 2113 8236 8013 4223 4005 2172 2342 4469 6821 2785 3275 2635 2188 3634 6363 2154 8013 8013 9616 8013 4223 8013 2428 4005 2298 2477 2066 4965 2505 2228 2420 8013 4223 8013 9616 4005 2963 2242 2093 3634 6363 2228 2093 4469 2420 2113 2242 7239 2066 7239 7239 2673 2568 2420 6698 7239 5166 3398 8013 8013 4223 8013 2093 4469 2420 3398 8013 4223 8013 9616 3398 2667 3828 2160 2428 2667 10647 18392 4005 4223 4005 2204 2028 8013 2425 4152 7823 2113 2699 4339 2242 3274 4933 3849 2066 2296 2733 2242 3310 3084 5263 4005 4223 4005 2092 6433 3599 6433 8013 4223 8013 2482 7807 8307 4152 5305 7239 4005 14910 14910 2228 2453 2131 2210 3805 2157 6433 8013 4223 8013 3599 4005 2785 2524 8013 8013 2583 2933 3828 2505 7965 2925 7239 2113 2154 2154 2518 4005 4223 4005 7239 4005 4510 2131 7239 8013 3398 2113 2564 2684 4005 4223 8013 5263 4005 3398 2524 2613 2524 2131 2172 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise cathy agent huh customer family usually far budget ##ing agent silence agent detailed budget husband finance major customer silence customer huh agent customer silence agent know money take month know food agent gas things like put aside much money month birthday ##s christmas things customer huh agent take major purchases want make year budget call ee ##ds needs wants list customer silence customer hum agent things like vacation vacation fund fund things need things want customer silence customer huh agent continually putting know month much going need know month going enough get particular item customer silence customer huh agent rarely buy anything credit everything buy paid customer silence customer yeah husband finance major also laughter kind plan one credit card every month put know amount retirement agent laughter agent silence customer budget new thing budget baby budget ##ing month allowance education starting agent right agent right customer budget every month newest addition thing far set amount take one big vacation year maybe know three small vacation ##s agent silence customer know exact amount spend year agent right customer agent found spend less money pull money instead writing checks things customer silence customer hum customer [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise cathy agent huh customer family usually far budget ##ing agent silence agent detailed budget husband finance major customer silence customer huh agent customer silence agent know money take month know food agent gas things like put aside much money month birthday ##s christmas things customer huh agent take major purchases want make year budget call ee ##ds needs wants list customer silence customer hum agent things like vacation vacation fund fund things need things want customer silence customer huh agent continually putting know month much going need know month going enough get particular item customer silence customer huh agent rarely buy anything credit everything buy paid customer silence customer yeah husband finance major also laughter kind plan one credit card every month put know amount retirement agent laughter agent silence customer budget new thing budget baby budget ##ing month allowance education starting agent right agent right customer budget every month newest addition thing far set amount take one big vacation year maybe know three small vacation ##s agent silence customer know exact amount spend year agent right customer agent found spend less money pull money instead writing checks things customer silence customer hum customer [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 18305 4005 9616 8013 2155 2788 2521 5166 2075 4005 4223 4005 6851 5166 3129 5446 2350 8013 4223 8013 9616 4005 8013 4223 4005 2113 2769 2202 3204 2113 2833 4005 3806 2477 2066 2404 4998 2172 2769 3204 5798 2015 4234 2477 8013 9616 4005 2202 2350 17402 2215 2191 2095 5166 2655 25212 5104 3791 4122 2862 8013 4223 8013 14910 4005 2477 2066 10885 10885 4636 4636 2477 2342 2477 2215 8013 4223 8013 9616 4005 14678 5128 2113 3204 2172 2183 2342 2113 3204 2183 2438 2131 3327 8875 8013 4223 8013 9616 4005 6524 4965 2505 4923 2673 4965 3825 8013 4223 8013 3398 3129 5446 2350 2036 7239 2785 2933 2028 4923 4003 2296 3204 2404 2113 3815 5075 4005 7239 4005 4223 8013 5166 2047 2518 5166 3336 5166 2075 3204 21447 2495 3225 4005 2157 4005 2157 8013 5166 2296 3204 14751 2804 2518 2521 2275 3815 2202 2028 2502 10885 2095 2672 2113 2093 2235 10885 2015 4005 4223 8013 2113 6635 3815 5247 2095 4005 2157 8013 4005 2179 5247 2625 2769 4139 2769 2612 3015 14148 2477 8013 4223 8013 14910 8013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 18305 4005 9616 8013 2155 2788 2521 5166 2075 4005 4223 4005 6851 5166 3129 5446 2350 8013 4223 8013 9616 4005 8013 4223 4005 2113 2769 2202 3204 2113 2833 4005 3806 2477 2066 2404 4998 2172 2769 3204 5798 2015 4234 2477 8013 9616 4005 2202 2350 17402 2215 2191 2095 5166 2655 25212 5104 3791 4122 2862 8013 4223 8013 14910 4005 2477 2066 10885 10885 4636 4636 2477 2342 2477 2215 8013 4223 8013 9616 4005 14678 5128 2113 3204 2172 2183 2342 2113 3204 2183 2438 2131 3327 8875 8013 4223 8013 9616 4005 6524 4965 2505 4923 2673 4965 3825 8013 4223 8013 3398 3129 5446 2350 2036 7239 2785 2933 2028 4923 4003 2296 3204 2404 2113 3815 5075 4005 7239 4005 4223 8013 5166 2047 2518 5166 3336 5166 2075 3204 21447 2495 3225 4005 2157 4005 2157 8013 5166 2296 3204 14751 2804 2518 2521 2275 3815 2202 2028 2502 10885 2095 2672 2113 2093 2235 10885 2015 4005 4223 8013 2113 6635 3815 5247 2095 4005 2157 8013 4005 2179 5247 2625 2769 4139 2769 2612 3015 14148 2477 8013 4223 8013 14910 8013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise guess give opinions first okay terms taxes guess feel like paying awful lot getting apparently little agent okay agent silence customer especially since things think taxes going guess opinion pp ##rop ##ria ##te necessarily appropriate things agent hum customer think emphasizing things like like education less programs permanent black holes never agent silence customer anything continue customer sponge ##s money agent hum customer mean need programs concept agent silence customer customer well like one concepts trying reno ##vate housing agent noise customer turning housing see agreed one often kind kind programs one made sense agent silence customer help people fix houses improve environment mean ro ##ject ##s projects idiot ##ic concept world agent hum agent silence customer sense ownership sense responsibility agent like warehouse almost customer well like place stay feeling responsibility ownership concern fact insult ing almost insulting mba ##rra ##ssing embarrassing agent silence agent hum agent silence customer know know exactly motivation ##s basically destroyed know people would st ##rew fe ##ces across customer rooms know incredible abuses occur ##ed obviously failed concept okay laughter yes think problems taxes laughter agent hum agent silence agent well noise huh agent silence agent well [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise guess give opinions first okay terms taxes guess feel like paying awful lot getting apparently little agent okay agent silence customer especially since things think taxes going guess opinion pp ##rop ##ria ##te necessarily appropriate things agent hum customer think emphasizing things like like education less programs permanent black holes never agent silence customer anything continue customer sponge ##s money agent hum customer mean need programs concept agent silence customer customer well like one concepts trying reno ##vate housing agent noise customer turning housing see agreed one often kind kind programs one made sense agent silence customer help people fix houses improve environment mean ro ##ject ##s projects idiot ##ic concept world agent hum agent silence customer sense ownership sense responsibility agent like warehouse almost customer well like place stay feeling responsibility ownership concern fact insult ing almost insulting mba ##rra ##ssing embarrassing agent silence agent hum agent silence customer know know exactly motivation ##s basically destroyed know people would st ##rew fe ##ces across customer rooms know incredible abuses occur ##ed obviously failed concept okay laughter yes think problems taxes laughter agent hum agent silence agent well noise huh agent silence agent well [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 3984 2507 10740 2034 3100 3408 7773 3984 2514 2066 7079 9643 2843 2893 4593 2210 4005 3100 4005 4223 8013 2926 2144 2477 2228 7773 2183 3984 5448 4903 18981 4360 2618 9352 6413 2477 4005 14910 8013 2228 22671 2477 2066 2066 2495 2625 3454 4568 2304 8198 2196 4005 4223 8013 2505 3613 8013 25742 2015 2769 4005 14910 8013 2812 2342 3454 4145 4005 4223 8013 8013 2092 2066 2028 8474 2667 17738 16952 3847 4005 5005 8013 3810 3847 2156 3530 2028 2411 2785 2785 3454 2028 2081 3168 4005 4223 8013 2393 2111 8081 3506 5335 4044 2812 20996 20614 2015 3934 10041 2594 4145 2088 4005 14910 4005 4223 8013 3168 6095 3168 5368 4005 2066 9746 2471 8013 2092 2066 2173 2994 3110 5368 6095 5142 2755 15301 13749 2471 23979 15038 11335 18965 16436 4005 4223 4005 14910 4005 4223 8013 2113 2113 3599 14354 2015 10468 3908 2113 2111 2052 2358 15603 10768 9623 2408 8013 4734 2113 9788 21078 5258 2098 5525 3478 4145 3100 7239 2748 2228 3471 7773 7239 4005 14910 4005 4223 4005 2092 5005 9616 4005 4223 4005 2092 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 3984 2507 10740 2034 3100 3408 7773 3984 2514 2066 7079 9643 2843 2893 4593 2210 4005 3100 4005 4223 8013 2926 2144 2477 2228 7773 2183 3984 5448 4903 18981 4360 2618 9352 6413 2477 4005 14910 8013 2228 22671 2477 2066 2066 2495 2625 3454 4568 2304 8198 2196 4005 4223 8013 2505 3613 8013 25742 2015 2769 4005 14910 8013 2812 2342 3454 4145 4005 4223 8013 8013 2092 2066 2028 8474 2667 17738 16952 3847 4005 5005 8013 3810 3847 2156 3530 2028 2411 2785 2785 3454 2028 2081 3168 4005 4223 8013 2393 2111 8081 3506 5335 4044 2812 20996 20614 2015 3934 10041 2594 4145 2088 4005 14910 4005 4223 8013 3168 6095 3168 5368 4005 2066 9746 2471 8013 2092 2066 2173 2994 3110 5368 6095 5142 2755 15301 13749 2471 23979 15038 11335 18965 16436 4005 4223 4005 14910 4005 4223 8013 2113 2113 3599 14354 2015 10468 3908 2113 2111 2052 2358 15603 10768 9623 2408 8013 4734 2113 9788 21078 5258 2098 5525 3478 4145 3100 7239 2748 2228 3471 7773 7239 4005 14910 4005 4223 4005 2092 5005 9616 4005 4223 4005 2092 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 38\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise well view work financial institution agent silence agent boy laughter customer yeah love credit card end consumer rights using credit cards agent silence agent mean customer mean say pay something check check clears bucks agent silence agent hum agent silence customer pay something credit card iss ##ati ##sf ##ied dissatisfied take back say sorry take back know leave visa charged back agent favorite credit card use visa come customer noise get money back customer silence customer visa customer well kind offer laughter agent silence agent good reason good reason customer silence customer offering new card gives one percent back charges make agent silence agent customer cash back know like discover agent silence agent gonna say know discover customer yep starting agent visa gonna customer agent right puts visa card customer silence customer noise america first credit union agent silence agent agent america first credit union gonna offer cash back like discover huh well tell works use discover card credit card sole reason customer silence customer yeah customer silence customer get much back agent noise yeah laughter unfortunately use discover card ought great deal get get check fifty bucks end year usually customer silence customer [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise well view work financial institution agent silence agent boy laughter customer yeah love credit card end consumer rights using credit cards agent silence agent mean customer mean say pay something check check clears bucks agent silence agent hum agent silence customer pay something credit card iss ##ati ##sf ##ied dissatisfied take back say sorry take back know leave visa charged back agent favorite credit card use visa come customer noise get money back customer silence customer visa customer well kind offer laughter agent silence agent good reason good reason customer silence customer offering new card gives one percent back charges make agent silence agent customer cash back know like discover agent silence agent gonna say know discover customer yep starting agent visa gonna customer agent right puts visa card customer silence customer noise america first credit union agent silence agent agent america first credit union gonna offer cash back like discover huh well tell works use discover card credit card sole reason customer silence customer yeah customer silence customer get much back agent noise yeah laughter unfortunately use discover card ought great deal get get check fifty bucks end year usually customer silence customer [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 2092 3193 2147 3361 5145 4005 4223 4005 2879 7239 8013 3398 2293 4923 4003 2203 7325 2916 2478 4923 5329 4005 4223 4005 2812 8013 2812 2360 3477 2242 4638 4638 28837 14189 4005 4223 4005 14910 4005 4223 8013 3477 2242 4923 4003 26354 10450 22747 6340 25956 2202 2067 2360 3374 2202 2067 2113 2681 9425 5338 2067 4005 5440 4923 4003 2224 9425 2272 8013 5005 2131 2769 2067 8013 4223 8013 9425 8013 2092 2785 3749 7239 4005 4223 4005 2204 3114 2204 3114 8013 4223 8013 5378 2047 4003 3957 2028 3867 2067 5571 2191 4005 4223 4005 8013 5356 2067 2113 2066 7523 4005 4223 4005 6069 2360 2113 7523 8013 15624 3225 4005 9425 6069 8013 4005 2157 8509 9425 4003 8013 4223 8013 5005 2637 2034 4923 2586 4005 4223 4005 4005 2637 2034 4923 2586 6069 3749 5356 2067 2066 7523 9616 2092 2425 2573 2224 7523 4003 4923 4003 7082 3114 8013 4223 8013 3398 8013 4223 8013 2131 2172 2067 4005 5005 3398 7239 6854 2224 7523 4003 11276 2307 3066 2131 2131 4638 5595 14189 2203 2095 2788 8013 4223 8013 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 2092 3193 2147 3361 5145 4005 4223 4005 2879 7239 8013 3398 2293 4923 4003 2203 7325 2916 2478 4923 5329 4005 4223 4005 2812 8013 2812 2360 3477 2242 4638 4638 28837 14189 4005 4223 4005 14910 4005 4223 8013 3477 2242 4923 4003 26354 10450 22747 6340 25956 2202 2067 2360 3374 2202 2067 2113 2681 9425 5338 2067 4005 5440 4923 4003 2224 9425 2272 8013 5005 2131 2769 2067 8013 4223 8013 9425 8013 2092 2785 3749 7239 4005 4223 4005 2204 3114 2204 3114 8013 4223 8013 5378 2047 4003 3957 2028 3867 2067 5571 2191 4005 4223 4005 8013 5356 2067 2113 2066 7523 4005 4223 4005 6069 2360 2113 7523 8013 15624 3225 4005 9425 6069 8013 4005 2157 8509 9425 4003 8013 4223 8013 5005 2637 2034 4923 2586 4005 4223 4005 4005 2637 2034 4923 2586 6069 3749 5356 2067 2066 7523 9616 2092 2425 2573 2224 7523 4003 4923 4003 7082 3114 8013 4223 8013 3398 8013 4223 8013 2131 2172 2067 4005 5005 3398 7239 6854 2224 7523 4003 11276 2307 3066 2131 2131 4638 5595 14189 2203 2095 2788 8013 4223 8013 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise agent vocal ##ized noise customer okay frank type customer budget family customer silence agent well know really budget set amount save actually well actually way budget money apparently agent wife agent much know gets much shopping every couple weeks agent all ##ot much money per week personal stuff gas things like besides know set amount save every every month customer right agent silence customer sounds like probably tighter controlled budget laughter single guess agent huh agent huh agent silence customer know excuse tight budget basically agent really need laughter customer right need laughter agent silence customer keep track makes little bit easier agent agent right customer also know try save certain amount month well agent silence agent hum agent silence customer kind customer kind idea expenses pretty consistent month month agent huh customer whenever need know whenever changes pretty well aware without actually maintain budget agent silence agent right customer silence agent silence agent well found know thing gotten older fifties use er ##y strict budget four kids agent know planned much going spend food much kind anti ##ci ##pate much things going agent guess one interesting aspect budget ##ing set aside like kind [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise agent vocal ##ized noise customer okay frank type customer budget family customer silence agent well know really budget set amount save actually well actually way budget money apparently agent wife agent much know gets much shopping every couple weeks agent all ##ot much money per week personal stuff gas things like besides know set amount save every every month customer right agent silence customer sounds like probably tighter controlled budget laughter single guess agent huh agent huh agent silence customer know excuse tight budget basically agent really need laughter customer right need laughter agent silence customer keep track makes little bit easier agent agent right customer also know try save certain amount month well agent silence agent hum agent silence customer kind customer kind idea expenses pretty consistent month month agent huh customer whenever need know whenever changes pretty well aware without actually maintain budget agent silence agent right customer silence agent silence agent well found know thing gotten older fifties use er ##y strict budget four kids agent know planned much going spend food much kind anti ##ci ##pate much things going agent guess one interesting aspect budget ##ing set aside like kind [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 4005 5554 3550 5005 8013 3100 3581 2828 8013 5166 2155 8013 4223 4005 2092 2113 2428 5166 2275 3815 3828 2941 2092 2941 2126 5166 2769 4593 4005 2564 4005 2172 2113 4152 2172 6023 2296 3232 3134 4005 2035 4140 2172 2769 2566 2733 3167 4933 3806 2477 2066 4661 2113 2275 3815 3828 2296 2296 3204 8013 2157 4005 4223 8013 4165 2066 2763 12347 4758 5166 7239 2309 3984 4005 9616 4005 9616 4005 4223 8013 2113 8016 4389 5166 10468 4005 2428 2342 7239 8013 2157 2342 7239 4005 4223 8013 2562 2650 3084 2210 2978 6082 4005 4005 2157 8013 2036 2113 3046 3828 3056 3815 3204 2092 4005 4223 4005 14910 4005 4223 8013 2785 8013 2785 2801 11727 3492 8335 3204 3204 4005 9616 8013 7188 2342 2113 7188 3431 3492 2092 5204 2302 2941 5441 5166 4005 4223 4005 2157 8013 4223 4005 4223 4005 2092 2179 2113 2518 5407 3080 25942 2224 9413 2100 9384 5166 2176 4268 4005 2113 3740 2172 2183 5247 2833 2172 2785 3424 6895 17585 2172 2477 2183 4005 3984 2028 5875 7814 5166 2075 2275 4998 2066 2785 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 4005 5554 3550 5005 8013 3100 3581 2828 8013 5166 2155 8013 4223 4005 2092 2113 2428 5166 2275 3815 3828 2941 2092 2941 2126 5166 2769 4593 4005 2564 4005 2172 2113 4152 2172 6023 2296 3232 3134 4005 2035 4140 2172 2769 2566 2733 3167 4933 3806 2477 2066 4661 2113 2275 3815 3828 2296 2296 3204 8013 2157 4005 4223 8013 4165 2066 2763 12347 4758 5166 7239 2309 3984 4005 9616 4005 9616 4005 4223 8013 2113 8016 4389 5166 10468 4005 2428 2342 7239 8013 2157 2342 7239 4005 4223 8013 2562 2650 3084 2210 2978 6082 4005 4005 2157 8013 2036 2113 3046 3828 3056 3815 3204 2092 4005 4223 4005 14910 4005 4223 8013 2785 8013 2785 2801 11727 3492 8335 3204 3204 4005 9616 8013 7188 2342 2113 7188 3431 3492 2092 5204 2302 2941 5441 5166 4005 4223 4005 2157 8013 4223 4005 4223 4005 2092 2179 2113 2518 5407 3080 25942 2224 9413 2100 9384 5166 2176 4268 4005 2113 3740 2172 2183 5247 2833 2172 2785 3424 6895 17585 2172 2477 2183 4005 3984 2028 5875 7814 5166 2075 2275 4998 2066 2785 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer silence customer agent silence customer think customer actually fairly pleased customer benefits customer working large corporation customer absolutely question important laughter benefit agent right customer noise think health care think everybody would say agent silence agent try get outside corporation gonna pay arm leg customer silence customer right belonging group belonging health group probably important protection noise agent silence agent right customer noise sometimes think important laughter salary agent silence agent also get dental customer laughter customer silence customer yes agent silence customer know would rank second since three boys turn important know given year dental dental expenses really kill agent know agent silence agent husband northwest airlines gets know full health dental four children pay teeth cleaned outrageous customer silence customer right agent know people afford customer silence customer right agent maybe laughter customer noise right agent silence customer cleaning get or ##th ##odon ##tics agent laughter right right laughter customer silence customer guess would sure would rank would rank next say compared retirement agent silence customer customer pre tax savings another thing think great great benefit noise agent huh agent right agent silence customer ea ##lly think really something government ought encourage complaints [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer silence customer agent silence customer think customer actually fairly pleased customer benefits customer working large corporation customer absolutely question important laughter benefit agent right customer noise think health care think everybody would say agent silence agent try get outside corporation gonna pay arm leg customer silence customer right belonging group belonging health group probably important protection noise agent silence agent right customer noise sometimes think important laughter salary agent silence agent also get dental customer laughter customer silence customer yes agent silence customer know would rank second since three boys turn important know given year dental dental expenses really kill agent know agent silence agent husband northwest airlines gets know full health dental four children pay teeth cleaned outrageous customer silence customer right agent know people afford customer silence customer right agent maybe laughter customer noise right agent silence customer cleaning get or ##th ##odon ##tics agent laughter right right laughter customer silence customer guess would sure would rank would rank next say compared retirement agent silence customer customer pre tax savings another thing think great great benefit noise agent huh agent right agent silence customer ea ##lly think really something government ought encourage complaints [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 4223 8013 4005 4223 8013 2228 8013 2941 7199 7537 8013 6666 8013 2551 2312 3840 8013 7078 3160 2590 7239 5770 4005 2157 8013 5005 2228 2740 2729 2228 7955 2052 2360 4005 4223 4005 3046 2131 2648 3840 6069 3477 2849 4190 8013 4223 8013 2157 7495 2177 7495 2740 2177 2763 2590 3860 5005 4005 4223 4005 2157 8013 5005 2823 2228 2590 7239 10300 4005 4223 4005 2036 2131 11394 8013 7239 8013 4223 8013 2748 4005 4223 8013 2113 2052 4635 2117 2144 2093 3337 2735 2590 2113 2445 2095 11394 11394 11727 2428 3102 4005 2113 4005 4223 4005 3129 4514 7608 4152 2113 2440 2740 11394 2176 2336 3477 4091 12176 25506 8013 4223 8013 2157 4005 2113 2111 8984 8013 4223 8013 2157 4005 2672 7239 8013 5005 2157 4005 4223 8013 9344 2131 2030 2705 28716 14606 4005 7239 2157 2157 7239 8013 4223 8013 3984 2052 2469 2052 4635 2052 4635 2279 2360 4102 5075 4005 4223 8013 8013 3653 4171 10995 2178 2518 2228 2307 2307 5770 5005 4005 9616 4005 2157 4005 4223 8013 19413 9215 2228 2428 2242 2231 11276 8627 10821 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 4223 8013 4005 4223 8013 2228 8013 2941 7199 7537 8013 6666 8013 2551 2312 3840 8013 7078 3160 2590 7239 5770 4005 2157 8013 5005 2228 2740 2729 2228 7955 2052 2360 4005 4223 4005 3046 2131 2648 3840 6069 3477 2849 4190 8013 4223 8013 2157 7495 2177 7495 2740 2177 2763 2590 3860 5005 4005 4223 4005 2157 8013 5005 2823 2228 2590 7239 10300 4005 4223 4005 2036 2131 11394 8013 7239 8013 4223 8013 2748 4005 4223 8013 2113 2052 4635 2117 2144 2093 3337 2735 2590 2113 2445 2095 11394 11394 11727 2428 3102 4005 2113 4005 4223 4005 3129 4514 7608 4152 2113 2440 2740 11394 2176 2336 3477 4091 12176 25506 8013 4223 8013 2157 4005 2113 2111 8984 8013 4223 8013 2157 4005 2672 7239 8013 5005 2157 4005 4223 8013 9344 2131 2030 2705 28716 14606 4005 7239 2157 2157 7239 8013 4223 8013 3984 2052 2469 2052 4635 2052 4635 2279 2360 4102 5075 4005 4223 8013 8013 3653 4171 10995 2178 2518 2228 2307 2307 5770 5005 4005 9616 4005 2157 4005 4223 8013 19413 9215 2228 2428 2242 2231 11276 8627 10821 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Job Benefits (id = 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Job Benefits (id = 4)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer right agent well like told laughter customer silence agent laughter agent talking noise credit cards customer hum agent noise put customer silence agent mean delightful evening one laughter night cutting bunch sucker ##s customer wish agent silence agent well try customer silence customer well done business going agent silence customer back eighties know remember gold silver prices customer coin shop customer everything going great gold silver started falling agent yeah customer started paying expenses stuff credit cards things got worse worse finally boom agent silence agent lost business laughter nightmare customer yep customer silence customer yeah yeah ended going bank ru ##pt ##cy know one things noise get better next week know noise things pick agent silence customer old bankruptcy court customer silence agent well charging gold silver agent silence customer yeah yeah agent noise customer yeah yeah buying dealers agent silence customer know take payment way get agent noise nightmare noise customer silence customer yeah course stuff vocal ##ized noise merchandise buying cards getting money back selling buying know hold onto agent silence customer customer things like know rent phone bills advertising customer good stuff ate agent customer agent well noise remember got married [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer right agent well like told laughter customer silence agent laughter agent talking noise credit cards customer hum agent noise put customer silence agent mean delightful evening one laughter night cutting bunch sucker ##s customer wish agent silence agent well try customer silence customer well done business going agent silence customer back eighties know remember gold silver prices customer coin shop customer everything going great gold silver started falling agent yeah customer started paying expenses stuff credit cards things got worse worse finally boom agent silence agent lost business laughter nightmare customer yep customer silence customer yeah yeah ended going bank ru ##pt ##cy know one things noise get better next week know noise things pick agent silence customer old bankruptcy court customer silence agent well charging gold silver agent silence customer yeah yeah agent noise customer yeah yeah buying dealers agent silence customer know take payment way get agent noise nightmare noise customer silence customer yeah course stuff vocal ##ized noise merchandise buying cards getting money back selling buying know hold onto agent silence customer customer things like know rent phone bills advertising customer good stuff ate agent customer agent well noise remember got married [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 2157 4005 2092 2066 2409 7239 8013 4223 4005 7239 4005 3331 5005 4923 5329 8013 14910 4005 5005 2404 8013 4223 4005 2812 26380 3944 2028 7239 2305 6276 9129 26476 2015 8013 4299 4005 4223 4005 2092 3046 8013 4223 8013 2092 2589 2449 2183 4005 4223 8013 2067 27690 2113 3342 2751 3165 7597 8013 9226 4497 8013 2673 2183 2307 2751 3165 2318 4634 4005 3398 8013 2318 7079 11727 4933 4923 5329 2477 2288 4788 4788 2633 8797 4005 4223 4005 2439 2449 7239 10103 8013 15624 8013 4223 8013 3398 3398 3092 2183 2924 21766 13876 5666 2113 2028 2477 5005 2131 2488 2279 2733 2113 5005 2477 4060 4005 4223 8013 2214 10528 2457 8013 4223 4005 2092 13003 2751 3165 4005 4223 8013 3398 3398 4005 5005 8013 3398 3398 9343 16743 4005 4223 8013 2113 2202 7909 2126 2131 4005 5005 10103 5005 8013 4223 8013 3398 2607 4933 5554 3550 5005 16359 9343 5329 2893 2769 2067 4855 9343 2113 2907 3031 4005 4223 8013 8013 2477 2066 2113 9278 3042 8236 6475 8013 2204 4933 8823 4005 8013 4005 2092 5005 3342 2288 2496 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 2157 4005 2092 2066 2409 7239 8013 4223 4005 7239 4005 3331 5005 4923 5329 8013 14910 4005 5005 2404 8013 4223 4005 2812 26380 3944 2028 7239 2305 6276 9129 26476 2015 8013 4299 4005 4223 4005 2092 3046 8013 4223 8013 2092 2589 2449 2183 4005 4223 8013 2067 27690 2113 3342 2751 3165 7597 8013 9226 4497 8013 2673 2183 2307 2751 3165 2318 4634 4005 3398 8013 2318 7079 11727 4933 4923 5329 2477 2288 4788 4788 2633 8797 4005 4223 4005 2439 2449 7239 10103 8013 15624 8013 4223 8013 3398 3398 3092 2183 2924 21766 13876 5666 2113 2028 2477 5005 2131 2488 2279 2733 2113 5005 2477 4060 4005 4223 8013 2214 10528 2457 8013 4223 4005 2092 13003 2751 3165 4005 4223 8013 3398 3398 4005 5005 8013 3398 3398 9343 16743 4005 4223 8013 2113 2202 7909 2126 2131 4005 5005 10103 5005 8013 4223 8013 3398 2607 4933 5554 3550 5005 16359 9343 5329 2893 2769 2067 4855 9343 2113 2907 3031 4005 4223 8013 8013 2477 2066 2113 9278 3042 8236 6475 8013 2204 4933 8823 4005 8013 4005 2092 5005 3342 2288 2496 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Credit Card (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer guess agent customer know diane lancaster ever meet wedding agent silence agent yeah blonde hair customer kay okay trans ##cr ##ib ##ing tapes agent silence agent kidding customer customer silence agent well diane laughter customer laughter really hey suzy agent laughter customer crazy well glad glad dear whenever first heard topic said hate talk finances budget agent silence agent laughter well customer laughter customer silence customer huh either covers agent silence agent agent funny customer know know agent funny third time third time done even chance call customer silence customer customer talked three different times agent huh third person customer silence customer yeah well great agent yeah got two two fellows somewhere customer silence customer yes agent never stay subject customer yeah laughter ave going say gotten first check yet agent laughter agent silence agent huh started week monday customer silence customer already two calls agent silence agent huh customer go ##sh agent third customer pretty good agent mean made call yet customer yeah well need start agent silence agent okay customer gain getting three calls made really done much agent silence agent right customer yeah agent record recording customer silence customer yeah recording agent [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer guess agent customer know diane lancaster ever meet wedding agent silence agent yeah blonde hair customer kay okay trans ##cr ##ib ##ing tapes agent silence agent kidding customer customer silence agent well diane laughter customer laughter really hey suzy agent laughter customer crazy well glad glad dear whenever first heard topic said hate talk finances budget agent silence agent laughter well customer laughter customer silence customer huh either covers agent silence agent agent funny customer know know agent funny third time third time done even chance call customer silence customer customer talked three different times agent huh third person customer silence customer yeah well great agent yeah got two two fellows somewhere customer silence customer yes agent never stay subject customer yeah laughter ave going say gotten first check yet agent laughter agent silence agent huh started week monday customer silence customer already two calls agent silence agent huh customer go ##sh agent third customer pretty good agent mean made call yet customer yeah well need start agent silence agent okay customer gain getting three calls made really done much agent silence agent right customer yeah agent record recording customer silence customer yeah recording agent [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 3984 4005 8013 2113 12082 10237 2412 3113 5030 4005 4223 4005 3398 9081 2606 8013 10905 3100 9099 26775 12322 2075 13324 4005 4223 4005 12489 8013 8013 4223 4005 2092 12082 7239 8013 7239 2428 4931 28722 4005 7239 8013 4689 2092 5580 5580 6203 7188 2034 2657 8476 2056 5223 2831 16156 5166 4005 4223 4005 7239 2092 8013 7239 8013 4223 8013 9616 2593 4472 4005 4223 4005 4005 6057 8013 2113 2113 4005 6057 2353 2051 2353 2051 2589 2130 3382 2655 8013 4223 8013 8013 5720 2093 2367 2335 4005 9616 2353 2711 8013 4223 8013 3398 2092 2307 4005 3398 2288 2048 2048 13572 4873 8013 4223 8013 2748 4005 2196 2994 3395 8013 3398 7239 13642 2183 2360 5407 2034 4638 2664 4005 7239 4005 4223 4005 9616 2318 2733 6928 8013 4223 8013 2525 2048 4455 4005 4223 4005 9616 8013 2175 4095 4005 2353 8013 3492 2204 4005 2812 2081 2655 2664 8013 3398 2092 2342 2707 4005 4223 4005 3100 8013 5114 2893 2093 4455 2081 2428 2589 2172 4005 4223 4005 2157 8013 3398 4005 2501 3405 8013 4223 8013 3398 3405 4005 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 3984 4005 8013 2113 12082 10237 2412 3113 5030 4005 4223 4005 3398 9081 2606 8013 10905 3100 9099 26775 12322 2075 13324 4005 4223 4005 12489 8013 8013 4223 4005 2092 12082 7239 8013 7239 2428 4931 28722 4005 7239 8013 4689 2092 5580 5580 6203 7188 2034 2657 8476 2056 5223 2831 16156 5166 4005 4223 4005 7239 2092 8013 7239 8013 4223 8013 9616 2593 4472 4005 4223 4005 4005 6057 8013 2113 2113 4005 6057 2353 2051 2353 2051 2589 2130 3382 2655 8013 4223 8013 8013 5720 2093 2367 2335 4005 9616 2353 2711 8013 4223 8013 3398 2092 2307 4005 3398 2288 2048 2048 13572 4873 8013 4223 8013 2748 4005 2196 2994 3395 8013 3398 7239 13642 2183 2360 5407 2034 4638 2664 4005 7239 4005 4223 4005 9616 2318 2733 6928 8013 4223 8013 2525 2048 4455 4005 4223 4005 9616 8013 2175 4095 4005 2353 8013 3492 2204 4005 2812 2081 2655 2664 8013 3398 2092 2342 2707 4005 4223 4005 3100 8013 5114 2893 2093 4455 2081 2428 2589 2172 4005 4223 4005 2157 8013 3398 4005 2501 3405 8013 4223 8013 3398 3405 4005 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb9RCzvxfthX",
        "outputId": "3f00dc80-f053-45d4-c85b-b70cfd3501b7"
      },
      "source": [
        "\n",
        "for (ex_index, example) in enumerate(train_InputExamples):\n",
        "    if ex_index % 10000 == 0:\n",
        "      print(ex_index, len(train_InputExamples))\n",
        "      print(example.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 192\n",
            "Family Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e1RV7WtftkN",
        "outputId": "44915d98-2113-44dd-d1a2-b4fa58199323"
      },
      "source": [
        "#Example on first observation in the training set\n",
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence :  agent noise customer noise customer keep budget agent silence agent noise really one commitment end month customer silence agent everything paid agent basically budget customer budget agent use credit cards let see else get customer silence agent get bill mail write check immediately customer yep agent put date outside envelope stick little franklin planner customer silence agent agent carry around day supposed mail mail way know much hole agent basically noise budget based agent noise agent noise bank account low spend much customer yeah agent silence customer noise customer wife customer new young couple starting trying noise budget getting lot customer lot tighter actually worked extensive year long budget agent wow customer know exactly gonna spend gonna money worked cash flow agent silence customer bought house another reason really keeping track pennies stuff agent yeah agent laughter customer laughter agent silence customer detailed budget ways really kind nice much worry much discussion customer real conflict whether always sense confidence little bit know going money said going agent yeah agent silence agent consensus customer silence customer yeah brother told accounting suggested agent ahead time huh agent silence customer making big financial steps stuff said well fight year worked budget going spend agent laughter agent good tried beginning hen hen say tried tried sit consensus customer silence customer agent agreed noise customer silence agent shall say best consensus could get pretty thrifty noise agent know watch spend money big items noise kind talk two agent noise playing russian roulette guess although married agent many years agent noise agent let see customer laughter agent twenty six twenty seven years customer silence customer ound sounds like guys gotten something worked gonna work fine agent silence agent well kind commitment spend much customer silence customer yeah agent noise customer silence agent budget idea sounds pretty good think ever agent one financial crisis know like agent emergency kind job loss something like noise neither one noise agent predict ing two bank accounts customer hum agent one wanted customer silence agent silence agent wanted learn balance checkbook agent agent noise best keep current speak gave another checkbook said okay account money anytime customer yeah customer silence agent want tell much account customer hum agent laughter said trying control said know six hundred dollars want another three hundred tell customer silence agent finally got one things get money agent company puts makes direct deposit customer yes agent noise give customer silence agent let see noise gets like third money household pay everything else agent silence customer yeah done see married three years customer wife real good checkbooks math stuff gave said everything customer come help agent think good customer silence customer really good know come appreciate understand going everything really quite nice actually laughter agent silence customer agent think good one friends suggested customer silence agent life would little easier around house even yet\n",
            "------------------------------\n",
            "Tokens :  ['agent', 'noise', 'customer', 'noise', 'customer', 'keep', 'budget', 'agent', 'silence', 'agent', 'noise', 'really', 'one', 'commitment', 'end', 'month', 'customer', 'silence', 'agent', 'everything', 'paid', 'agent', 'basically', 'budget', 'customer', 'budget', 'agent', 'use', 'credit', 'cards', 'let', 'see', 'else', 'get', 'customer', 'silence', 'agent', 'get', 'bill', 'mail', 'write', 'check', 'immediately', 'customer', 'yep', 'agent', 'put', 'date', 'outside', 'envelope', 'stick', 'little', 'franklin', 'planner', 'customer', 'silence', 'agent', 'agent', 'carry', 'around', 'day', 'supposed', 'mail', 'mail', 'way', 'know', 'much', 'hole', 'agent', 'basically', 'noise', 'budget', 'based', 'agent', 'noise', 'agent', 'noise', 'bank', 'account', 'low', 'spend', 'much', 'customer', 'yeah', 'agent', 'silence', 'customer', 'noise', 'customer', 'wife', 'customer', 'new', 'young', 'couple', 'starting', 'trying', 'noise', 'budget', 'getting', 'lot', 'customer', 'lot', 'tighter', 'actually', 'worked', 'extensive', 'year', 'long', 'budget', 'agent', 'wow', 'customer', 'know', 'exactly', 'gonna', 'spend', 'gonna', 'money', 'worked', 'cash', 'flow', 'agent', 'silence', 'customer', 'bought', 'house', 'another', 'reason', 'really', 'keeping', 'track', 'penn', '##ies', 'stuff', 'agent', 'yeah', 'agent', 'laughter', 'customer', 'laughter', 'agent', 'silence', 'customer', 'detailed', 'budget', 'ways', 'really', 'kind', 'nice', 'much', 'worry', 'much', 'discussion', 'customer', 'real', 'conflict', 'whether', 'always', 'sense', 'confidence', 'little', 'bit', 'know', 'going', 'money', 'said', 'going', 'agent', 'yeah', 'agent', 'silence', 'agent', 'consensus', 'customer', 'silence', 'customer', 'yeah', 'brother', 'told', 'accounting', 'suggested', 'agent', 'ahead', 'time', 'huh', 'agent', 'silence', 'customer', 'making', 'big', 'financial', 'steps', 'stuff', 'said', 'well', 'fight', 'year', 'worked', 'budget', 'going', 'spend', 'agent', 'laughter', 'agent', 'good', 'tried', 'beginning', 'hen', 'hen', 'say', 'tried', 'tried', 'sit', 'consensus', 'customer', 'silence', 'customer', 'agent', 'agreed', 'noise', 'customer', 'silence', 'agent', 'shall', 'say', 'best', 'consensus', 'could', 'get', 'pretty', 'th', '##rift', '##y', 'noise', 'agent', 'know', 'watch', 'spend', 'money', 'big', 'items', 'noise', 'kind', 'talk', 'two', 'agent', 'noise', 'playing', 'russian', 'ro', '##ule', '##tte', 'guess', 'although', 'married', 'agent', 'many', 'years', 'agent', 'noise', 'agent', 'let', 'see', 'customer', 'laughter', 'agent', 'twenty', 'six', 'twenty', 'seven', 'years', 'customer', 'silence', 'customer', 'ou', '##nd', 'sounds', 'like', 'guys', 'gotten', 'something', 'worked', 'gonna', 'work', 'fine', 'agent', 'silence', 'agent', 'well', 'kind', 'commitment', 'spend', 'much', 'customer', 'silence', 'customer', 'yeah', 'agent', 'noise', 'customer', 'silence', 'agent', 'budget', 'idea', 'sounds', 'pretty', 'good', 'think', 'ever', 'agent', 'one', 'financial', 'crisis', 'know', 'like', 'agent', 'emergency', 'kind', 'job', 'loss', 'something', 'like', 'noise', 'neither', 'one', 'noise', 'agent', 'predict', 'ing', 'two', 'bank', 'accounts', 'customer', 'hum', 'agent', 'one', 'wanted', 'customer', 'silence', 'agent', 'silence', 'agent', 'wanted', 'learn', 'balance', 'check', '##book', 'agent', 'agent', 'noise', 'best', 'keep', 'current', 'speak', 'gave', 'another', 'check', '##book', 'said', 'okay', 'account', 'money', 'anytime', 'customer', 'yeah', 'customer', 'silence', 'agent', 'want', 'tell', 'much', 'account', 'customer', 'hum', 'agent', 'laughter', 'said', 'trying', 'control', 'said', 'know', 'six', 'hundred', 'dollars', 'want', 'another', 'three', 'hundred', 'tell', 'customer', 'silence', 'agent', 'finally', 'got', 'one', 'things', 'get', 'money', 'agent', 'company', 'puts', 'makes', 'direct', 'deposit', 'customer', 'yes', 'agent', 'noise', 'give', 'customer', 'silence', 'agent', 'let', 'see', 'noise', 'gets', 'like', 'third', 'money', 'household', 'pay', 'everything', 'else', 'agent', 'silence', 'customer', 'yeah', 'done', 'see', 'married', 'three', 'years', 'customer', 'wife', 'real', 'good', 'check', '##books', 'math', 'stuff', 'gave', 'said', 'everything', 'customer', 'come', 'help', 'agent', 'think', 'good', 'customer', 'silence', 'customer', 'really', 'good', 'know', 'come', 'appreciate', 'understand', 'going', 'everything', 'really', 'quite', 'nice', 'actually', 'laughter', 'agent', 'silence', 'customer', 'agent', 'think', 'good', 'one', 'friends', 'suggested', 'customer', 'silence', 'agent', 'life', 'would', 'little', 'easier', 'around', 'house', 'even', 'yet']\n",
            "------------------------------\n",
            "Input IDs :  [101, 4005, 5005, 8013, 5005, 8013, 2562, 5166, 4005, 4223, 4005, 5005, 2428, 2028, 8426, 2203, 3204, 8013, 4223, 4005, 2673, 3825, 4005, 10468, 5166, 8013, 5166, 4005, 2224, 4923, 5329, 2292, 2156, 2842, 2131, 8013, 4223, 4005, 2131, 3021, 5653, 4339, 4638, 3202, 8013, 15624, 4005, 2404, 3058, 2648, 11255, 6293, 2210, 5951, 24555, 8013, 4223, 4005, 4005, 4287, 2105, 2154, 4011, 5653, 5653, 2126, 2113, 2172, 4920, 4005, 10468, 5005, 5166, 2241, 4005, 5005, 4005, 5005, 2924, 4070, 2659, 5247, 2172, 8013, 3398, 4005, 4223, 8013, 5005, 8013, 2564, 8013, 2047, 2402, 3232, 3225, 2667, 5005, 5166, 2893, 2843, 8013, 2843, 12347, 2941, 2499, 4866, 2095, 2146, 5166, 4005, 10166, 8013, 2113, 3599, 6069, 5247, 6069, 2769, 2499, 5356, 4834, 4005, 4223, 8013, 4149, 2160, 2178, 3114, 2428, 4363, 2650, 9502, 3111, 4933, 4005, 3398, 4005, 7239, 8013, 7239, 4005, 4223, 8013, 6851, 5166, 3971, 2428, 2785, 3835, 2172, 4737, 2172, 6594, 8013, 2613, 4736, 3251, 2467, 3168, 7023, 2210, 2978, 2113, 2183, 2769, 2056, 2183, 4005, 3398, 4005, 4223, 4005, 10465, 8013, 4223, 8013, 3398, 2567, 2409, 9529, 4081, 4005, 3805, 2051, 9616, 4005, 4223, 8013, 2437, 2502, 3361, 4084, 4933, 2056, 2092, 2954, 2095, 2499, 102]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3FkKga_ftnB"
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \n",
        "    bert_module = hub.Module(\n",
        "        BERT_MODEL_HUB,\n",
        "        trainable=True)\n",
        "    bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "    # Use \"sequence_outputs\" for token-level output.\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "    # with tf.Session() as sess:\n",
        "    output_layer1 = bert_outputs[\"pooled_output\"]\n",
        "    # output_layer1 = 999\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    # Create our own layer to tune for politeness data.\n",
        "    output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "\n",
        "        # Dropout helps prevent overfitting\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "        # Convert labels into one-hot encoding\n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs, output_layer1)\n",
        "\n",
        "        # If we're train/eval, compute loss between predicted and actual label\n",
        "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        \n",
        "        return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm2bUpQ1jZtJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-9HbueWjZv0"
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "    \n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "\n",
        "        # TRAIN and EVAL\n",
        "        if not is_predicting:\n",
        "\n",
        "            (loss, predicted_labels, log_probs) = create_model(\n",
        "            is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            train_op = optimization.create_optimizer(\n",
        "              loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "            # Calculate evaluation metrics. \n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                true_pos = tf.metrics.true_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_neg = tf.metrics.true_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)   \n",
        "                false_pos = tf.metrics.false_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)  \n",
        "                false_neg = tf.metrics.false_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"true_positives\": true_pos,\n",
        "                    \"true_negatives\": true_neg,\n",
        "                    \"false_positives\": false_pos,\n",
        "                    \"false_negatives\": false_neg,\n",
        "                    }\n",
        "\n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                  loss=loss,\n",
        "                  train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                    loss=loss,\n",
        "                    eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs, output_layer) = create_model(\n",
        "            is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "            predictions = {\n",
        "              'probabilities': log_probs,\n",
        "              'labels': predicted_labels,\n",
        "              'pooled_output': output_layer\n",
        "            }\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6inaKufujZ0M"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWm0HWDijZ4o",
        "outputId": "23c7fe3c-3b6b-4d3b-c63b-64ff3a90d115"
      },
      "source": [
        "num_train_steps, len(label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "1Nvy_fdS68J5",
        "outputId": "1943838f-db5d-4827-f6c9-293269992d30"
      },
      "source": [
        "model_fn.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f7540152d26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9o--3PQjZ7g",
        "outputId": "2e56b866-d7e5-4aa9-d5b8-dcdad40be88f"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './bert_conersation_tagging', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa711c2f810>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './bert_conersation_tagging', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa711c2f810>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxb3ynmljZ-q"
      },
      "source": [
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRfD2cHxkBIZ",
        "outputId": "fe055ca3-e900-4582-b115-6d5d7e7297cd"
      },
      "source": [
        "# Training\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-51-d311bc1ecf48>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-51-d311bc1ecf48>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into ./bert_conersation_tagging/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into ./bert_conersation_tagging/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.8476584, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.8476584, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3 vs previous value: 3. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3 vs previous value: 3. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 12 into ./bert_conersation_tagging/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 12 into ./bert_conersation_tagging/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 1.6573584.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 1.6573584.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:08:41.599019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZcSH3vakBLq",
        "outputId": "73a39470-d0f3-435d-eea8-6b24376c4928"
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-03T11:07:35Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-03T11:07:35Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-03-11:08:33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-03-11:08:33\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 12: eval_accuracy = 0.28947368, false_negatives = 0.0, false_positives = 1.0, global_step = 12, loss = 1.6520232, true_negatives = 0.0, true_positives = 37.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 12: eval_accuracy = 0.28947368, false_negatives = 0.0, false_positives = 1.0, global_step = 12, loss = 1.6520232, true_negatives = 0.0, true_positives = 37.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12: ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12: ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.28947368,\n",
              " 'false_negatives': 0.0,\n",
              " 'false_positives': 1.0,\n",
              " 'global_step': 12,\n",
              " 'loss': 1.6520232,\n",
              " 'true_negatives': 0.0,\n",
              " 'true_positives': 37.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrmvUibQ2-5Q"
      },
      "source": [
        "test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nv-0NS0kBOJ",
        "outputId": "72c32b56-6bb6-4409-f815-9a99f39d280b"
      },
      "source": [
        "test_features = run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise customer ahead tell think get money worth agent silence agent hey listen way pay taxes things hear tax money going lu ##dic ##rous things customer silence customer yeah see sixty minutes last night agent customer well noise thing thirty five billion dollars waste every year storing stuff military need agent silence agent well grab grab customer staggering customer silence agent mean lady heard christian program agent ne ##a national endowment arts fund agent funded thing act stage study two lesbian ##s two homosexual ##s wrote report money customer well lot things people think generally agent silence agent frost ##s terribly customer silence customer well think interesting look agent silence customer money vocal ##ized noise goes goes lot places probably ought think generally think interesting agent absolutely agent silence customer noise probably represent majority people country terms feelings government serves given extra ##ord ##ina ##rily large sum money government operate agent believe true yes customer think gonna really interesting mean gonna change people represent agent silence agent correct customer mean think gonna real interesting see force upon agent silence agent heavy involvement public customer yeah right think thing gonna change agent hum agent yeah heavy [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise customer ahead tell think get money worth agent silence agent hey listen way pay taxes things hear tax money going lu ##dic ##rous things customer silence customer yeah see sixty minutes last night agent customer well noise thing thirty five billion dollars waste every year storing stuff military need agent silence agent well grab grab customer staggering customer silence agent mean lady heard christian program agent ne ##a national endowment arts fund agent funded thing act stage study two lesbian ##s two homosexual ##s wrote report money customer well lot things people think generally agent silence agent frost ##s terribly customer silence customer well think interesting look agent silence customer money vocal ##ized noise goes goes lot places probably ought think generally think interesting agent absolutely agent silence customer noise probably represent majority people country terms feelings government serves given extra ##ord ##ina ##rily large sum money government operate agent believe true yes customer think gonna really interesting mean gonna change people represent agent silence agent correct customer mean think gonna real interesting see force upon agent silence agent heavy involvement public customer yeah right think thing gonna change agent hum agent yeah heavy [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 8013 3805 2425 2228 2131 2769 4276 4005 4223 4005 4931 4952 2126 3477 7773 2477 2963 4171 2769 2183 11320 14808 13288 2477 8013 4223 8013 3398 2156 8442 2781 2197 2305 4005 8013 2092 5005 2518 4228 2274 4551 6363 5949 2296 2095 23977 4933 2510 2342 4005 4223 4005 2092 6723 6723 8013 26233 8013 4223 4005 2812 3203 2657 3017 2565 4005 11265 2050 2120 15108 2840 4636 4005 6787 2518 2552 2754 2817 2048 11690 2015 2048 15667 2015 2626 3189 2769 8013 2092 2843 2477 2111 2228 3227 4005 4223 4005 10097 2015 16668 8013 4223 8013 2092 2228 5875 2298 4005 4223 8013 2769 5554 3550 5005 3632 3632 2843 3182 2763 11276 2228 3227 2228 5875 4005 7078 4005 4223 8013 5005 2763 5050 3484 2111 2406 3408 5346 2231 4240 2445 4469 8551 3981 11272 2312 7680 2769 2231 5452 4005 2903 2995 2748 8013 2228 6069 2428 5875 2812 6069 2689 2111 5050 4005 4223 4005 6149 8013 2812 2228 6069 2613 5875 2156 2486 2588 4005 4223 4005 3082 6624 2270 8013 3398 2157 2228 2518 6069 2689 4005 14910 4005 3398 3082 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 8013 3805 2425 2228 2131 2769 4276 4005 4223 4005 4931 4952 2126 3477 7773 2477 2963 4171 2769 2183 11320 14808 13288 2477 8013 4223 8013 3398 2156 8442 2781 2197 2305 4005 8013 2092 5005 2518 4228 2274 4551 6363 5949 2296 2095 23977 4933 2510 2342 4005 4223 4005 2092 6723 6723 8013 26233 8013 4223 4005 2812 3203 2657 3017 2565 4005 11265 2050 2120 15108 2840 4636 4005 6787 2518 2552 2754 2817 2048 11690 2015 2048 15667 2015 2626 3189 2769 8013 2092 2843 2477 2111 2228 3227 4005 4223 4005 10097 2015 16668 8013 4223 8013 2092 2228 5875 2298 4005 4223 8013 2769 5554 3550 5005 3632 3632 2843 3182 2763 11276 2228 3227 2228 5875 4005 7078 4005 4223 8013 5005 2763 5050 3484 2111 2406 3408 5346 2231 4240 2445 4469 8551 3981 11272 2312 7680 2769 2231 5452 4005 2903 2995 2748 8013 2228 6069 2428 5875 2812 6069 2689 2111 5050 4005 4223 4005 6149 8013 2812 2228 6069 2613 5875 2156 2486 2588 4005 4223 4005 3082 6624 2270 8013 3398 2157 2228 2518 6069 2689 4005 14910 4005 3398 3082 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer silence customer yes agent silence customer noise customer guess noise customer initial view customer tax burden gone recent years despite total tax burden despite tax cuts customer among industrial ##ized nations one customer lowest world part matter get pay gonna national health insurance seems likely necessarily gonna involve taxes customer suspect take view cutting income tax rates good economy countries higher share tax burden customer various kinds sales taxes customer noise energy taxes particularly extent need raise taxes direction look customer silence agent right well guess kind mixed feelings laughter customer laughter agent know always sit pay check much comes wonder know going huge national deficit customer silence customer going customer silence agent guess lot times questions wondering well whole lot good know lot social programs need help agent kind always wonder well money going laughter agent silence customer well one one one big tax gone lot year social security tax principle going big trust fund agent hum agent silence customer particularly reg ##ress ##ive tax tax first dollar earnings customer senator mo ##yn ##ih ##an proposal cut think wo ##u makes lot sense agent sorry ou ##ld ##n hear customer think senator mo ##yn [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer silence customer yes agent silence customer noise customer guess noise customer initial view customer tax burden gone recent years despite total tax burden despite tax cuts customer among industrial ##ized nations one customer lowest world part matter get pay gonna national health insurance seems likely necessarily gonna involve taxes customer suspect take view cutting income tax rates good economy countries higher share tax burden customer various kinds sales taxes customer noise energy taxes particularly extent need raise taxes direction look customer silence agent right well guess kind mixed feelings laughter customer laughter agent know always sit pay check much comes wonder know going huge national deficit customer silence customer going customer silence agent guess lot times questions wondering well whole lot good know lot social programs need help agent kind always wonder well money going laughter agent silence customer well one one one big tax gone lot year social security tax principle going big trust fund agent hum agent silence customer particularly reg ##ress ##ive tax tax first dollar earnings customer senator mo ##yn ##ih ##an proposal cut think wo ##u makes lot sense agent sorry ou ##ld ##n hear customer think senator mo ##yn [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 4223 8013 2748 4005 4223 8013 5005 8013 3984 5005 8013 3988 3193 8013 4171 10859 2908 3522 2086 2750 2561 4171 10859 2750 4171 7659 8013 2426 3919 3550 3741 2028 8013 7290 2088 2112 3043 2131 3477 6069 2120 2740 5427 3849 3497 9352 6069 9125 7773 8013 8343 2202 3193 6276 3318 4171 6165 2204 4610 3032 3020 3745 4171 10859 8013 2536 7957 4341 7773 8013 5005 2943 7773 3391 6698 2342 5333 7773 3257 2298 8013 4223 4005 2157 2092 3984 2785 3816 5346 7239 8013 7239 4005 2113 2467 4133 3477 4638 2172 3310 4687 2113 2183 4121 2120 15074 8013 4223 8013 2183 8013 4223 4005 3984 2843 2335 3980 6603 2092 2878 2843 2204 2113 2843 2591 3454 2342 2393 4005 2785 2467 4687 2092 2769 2183 7239 4005 4223 8013 2092 2028 2028 2028 2502 4171 2908 2843 2095 2591 3036 4171 6958 2183 2502 3404 4636 4005 14910 4005 4223 8013 3391 19723 8303 3512 4171 4171 2034 7922 16565 8013 5205 9587 6038 19190 2319 6378 3013 2228 24185 2226 3084 2843 3168 4005 3374 15068 6392 2078 2963 8013 2228 5205 9587 6038 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 4223 8013 2748 4005 4223 8013 5005 8013 3984 5005 8013 3988 3193 8013 4171 10859 2908 3522 2086 2750 2561 4171 10859 2750 4171 7659 8013 2426 3919 3550 3741 2028 8013 7290 2088 2112 3043 2131 3477 6069 2120 2740 5427 3849 3497 9352 6069 9125 7773 8013 8343 2202 3193 6276 3318 4171 6165 2204 4610 3032 3020 3745 4171 10859 8013 2536 7957 4341 7773 8013 5005 2943 7773 3391 6698 2342 5333 7773 3257 2298 8013 4223 4005 2157 2092 3984 2785 3816 5346 7239 8013 7239 4005 2113 2467 4133 3477 4638 2172 3310 4687 2113 2183 4121 2120 15074 8013 4223 8013 2183 8013 4223 4005 3984 2843 2335 3980 6603 2092 2878 2843 2204 2113 2843 2591 3454 2342 2393 4005 2785 2467 4687 2092 2769 2183 7239 4005 4223 8013 2092 2028 2028 2028 2502 4171 2908 2843 2095 2591 3036 4171 6958 2183 2502 3404 4636 4005 14910 4005 4223 8013 3391 19723 8303 3512 4171 4171 2034 7922 16565 8013 5205 9587 6038 19190 2319 6378 3013 2228 24185 2226 3084 2843 3168 4005 3374 15068 6392 2078 2963 8013 2228 5205 9587 6038 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise laughter good laughter laughter laughter laughter laughter good laughter day customer noise customer vocal ##ized noise customer laughter customer went noise agent silence customer turned mine twelve hours early noon agent know finished mine eleven left carolyn hope turned customer silence customer laughter eating agent silence agent noise ahead stop eating barely got home university barely got home university customer silence customer kay customer say customer silence customer noise agent silence customer tell punch one five minutes voice comes talk night want laughter agent laughter okay ahead customer silence agent fire away customer noise agent noise customer love irony agent silence customer talking subject april fifteenth customer afraid probably minority actually think pay much country customer particularly part country er ##e guess agent agree agent silence customer bone pick way taxes distributed customer finished fu ##ming fact pay eight half percent sales tax income tax income tax could de ##ducted federal form customer sales tax think reg ##ress ##ive customer customer kind dumb customer silence agent hate eight half percent sales tax hand mind agent know things agent like noise groceries customer well mean nobody taxes groceries agent silence agent yeah agent arizona customer right agent [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise laughter good laughter laughter laughter laughter laughter good laughter day customer noise customer vocal ##ized noise customer laughter customer went noise agent silence customer turned mine twelve hours early noon agent know finished mine eleven left carolyn hope turned customer silence customer laughter eating agent silence agent noise ahead stop eating barely got home university barely got home university customer silence customer kay customer say customer silence customer noise agent silence customer tell punch one five minutes voice comes talk night want laughter agent laughter okay ahead customer silence agent fire away customer noise agent noise customer love irony agent silence customer talking subject april fifteenth customer afraid probably minority actually think pay much country customer particularly part country er ##e guess agent agree agent silence customer bone pick way taxes distributed customer finished fu ##ming fact pay eight half percent sales tax income tax income tax could de ##ducted federal form customer sales tax think reg ##ress ##ive customer customer kind dumb customer silence agent hate eight half percent sales tax hand mind agent know things agent like noise groceries customer well mean nobody taxes groceries agent silence agent yeah agent arizona customer right agent [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 7239 2204 7239 7239 7239 7239 7239 2204 7239 2154 8013 5005 8013 5554 3550 5005 8013 7239 8013 2253 5005 4005 4223 8013 2357 3067 4376 2847 2220 11501 4005 2113 2736 3067 5408 2187 15611 3246 2357 8013 4223 8013 7239 5983 4005 4223 4005 5005 3805 2644 5983 4510 2288 2188 2118 4510 2288 2188 2118 8013 4223 8013 10905 8013 2360 8013 4223 8013 5005 4005 4223 8013 2425 8595 2028 2274 2781 2376 3310 2831 2305 2215 7239 4005 7239 3100 3805 8013 4223 4005 2543 2185 8013 5005 4005 5005 8013 2293 19728 4005 4223 8013 3331 3395 2258 16249 8013 4452 2763 7162 2941 2228 3477 2172 2406 8013 3391 2112 2406 9413 2063 3984 4005 5993 4005 4223 8013 5923 4060 2126 7773 5500 8013 2736 11865 6562 2755 3477 2809 2431 3867 4341 4171 3318 4171 3318 4171 2071 2139 29510 2976 2433 8013 4341 4171 2228 19723 8303 3512 8013 8013 2785 12873 8013 4223 4005 5223 2809 2431 3867 4341 4171 2192 2568 4005 2113 2477 4005 2066 5005 26298 8013 2092 2812 6343 7773 26298 4005 4223 4005 3398 4005 5334 8013 2157 4005 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 7239 2204 7239 7239 7239 7239 7239 2204 7239 2154 8013 5005 8013 5554 3550 5005 8013 7239 8013 2253 5005 4005 4223 8013 2357 3067 4376 2847 2220 11501 4005 2113 2736 3067 5408 2187 15611 3246 2357 8013 4223 8013 7239 5983 4005 4223 4005 5005 3805 2644 5983 4510 2288 2188 2118 4510 2288 2188 2118 8013 4223 8013 10905 8013 2360 8013 4223 8013 5005 4005 4223 8013 2425 8595 2028 2274 2781 2376 3310 2831 2305 2215 7239 4005 7239 3100 3805 8013 4223 4005 2543 2185 8013 5005 4005 5005 8013 2293 19728 4005 4223 8013 3331 3395 2258 16249 8013 4452 2763 7162 2941 2228 3477 2172 2406 8013 3391 2112 2406 9413 2063 3984 4005 5993 4005 4223 8013 5923 4060 2126 7773 5500 8013 2736 11865 6562 2755 3477 2809 2431 3867 4341 4171 3318 4171 3318 4171 2071 2139 29510 2976 2433 8013 4341 4171 2228 19723 8303 3512 8013 8013 2785 12873 8013 4223 4005 5223 2809 2431 3867 4341 4171 2192 2568 4005 2113 2477 4005 2066 5005 26298 8013 2092 2812 6343 7773 26298 4005 4223 4005 3398 4005 5334 8013 2157 4005 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer get going agent okay customer noise customer austin agent silence agent well left january signed customer silence customer great daughter talked daughter another one talked students guess agent silence customer sent customers people colleges things computer user daughter talked two students non tier ##s guess yeah agent think good idea agent right customer finances retired agent silence agent laughter actually left basically set sights leave announced would salary increases ninety one customer customer silence agent def in ##ite ##ly definitely need make little money really accomplished yet trying customer yeah customer silence customer yeah finances guess subject finances tough going fifteen years year tough thing agent silence customer salary thing quite always right well financial budget well lot information budget agent wish hope person things better budget one goals year try get good customer silence agent long range planning budget mode single mom trying get customer well deserve honor gold star guess laughter agent silence agent laughter thank nice someone understand customer silence customer right sure agent budget live customer silence customer well guess long term budget be ##c aus ##e got daughter college one going college thinking quite nt ##hly monthly tell funny story [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent silence customer get going agent okay customer noise customer austin agent silence agent well left january signed customer silence customer great daughter talked daughter another one talked students guess agent silence customer sent customers people colleges things computer user daughter talked two students non tier ##s guess yeah agent think good idea agent right customer finances retired agent silence agent laughter actually left basically set sights leave announced would salary increases ninety one customer customer silence agent def in ##ite ##ly definitely need make little money really accomplished yet trying customer yeah customer silence customer yeah finances guess subject finances tough going fifteen years year tough thing agent silence customer salary thing quite always right well financial budget well lot information budget agent wish hope person things better budget one goals year try get good customer silence agent long range planning budget mode single mom trying get customer well deserve honor gold star guess laughter agent silence agent laughter thank nice someone understand customer silence customer right sure agent budget live customer silence customer well guess long term budget be ##c aus ##e got daughter college one going college thinking quite nt ##hly monthly tell funny story [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 2131 2183 4005 3100 8013 5005 8013 5899 4005 4223 4005 2092 2187 2254 2772 8013 4223 8013 2307 2684 5720 2684 2178 2028 5720 2493 3984 4005 4223 8013 2741 6304 2111 6667 2477 3274 5310 2684 5720 2048 2493 2512 7563 2015 3984 3398 4005 2228 2204 2801 4005 2157 8013 16156 3394 4005 4223 4005 7239 2941 2187 10468 2275 15925 2681 2623 2052 10300 7457 13568 2028 8013 8013 4223 4005 13366 1999 4221 2135 5791 2342 2191 2210 2769 2428 8885 2664 2667 8013 3398 8013 4223 8013 3398 16156 3984 3395 16156 7823 2183 5417 2086 2095 7823 2518 4005 4223 8013 10300 2518 3243 2467 2157 2092 3361 5166 2092 2843 2592 5166 4005 4299 3246 2711 2477 2488 5166 2028 3289 2095 3046 2131 2204 8013 4223 4005 2146 2846 4041 5166 5549 2309 3566 2667 2131 8013 2092 10107 3932 2751 2732 3984 7239 4005 4223 4005 7239 4067 3835 2619 3305 8013 4223 8013 2157 2469 4005 5166 2444 8013 4223 8013 2092 3984 2146 2744 5166 2022 2278 17151 2063 2288 2684 2267 2028 2183 2267 3241 3243 23961 27732 7058 2425 6057 2466 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 4223 8013 2131 2183 4005 3100 8013 5005 8013 5899 4005 4223 4005 2092 2187 2254 2772 8013 4223 8013 2307 2684 5720 2684 2178 2028 5720 2493 3984 4005 4223 8013 2741 6304 2111 6667 2477 3274 5310 2684 5720 2048 2493 2512 7563 2015 3984 3398 4005 2228 2204 2801 4005 2157 8013 16156 3394 4005 4223 4005 7239 2941 2187 10468 2275 15925 2681 2623 2052 10300 7457 13568 2028 8013 8013 4223 4005 13366 1999 4221 2135 5791 2342 2191 2210 2769 2428 8885 2664 2667 8013 3398 8013 4223 8013 3398 16156 3984 3395 16156 7823 2183 5417 2086 2095 7823 2518 4005 4223 8013 10300 2518 3243 2467 2157 2092 3361 5166 2092 2843 2592 5166 4005 4299 3246 2711 2477 2488 5166 2028 3289 2095 3046 2131 2204 8013 4223 4005 2146 2846 4041 5166 5549 2309 3566 2667 2131 8013 2092 10107 3932 2751 2732 3984 7239 4005 4223 4005 7239 4067 3835 2619 3305 8013 4223 8013 2157 2469 4005 5166 2444 8013 4223 8013 2092 3984 2146 2744 5166 2022 2278 17151 2063 2288 2684 2267 2028 2183 2267 3241 3243 23961 27732 7058 2425 6057 2466 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Family Finance (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise steve election year what ##not coming think ought cut taxes raise think agent silence agent well laughter really hard question know politicians always talking sides mouths customer silence agent noise let example friend president right says new taxes especially anything cutting taxes recession time budget sent congress agent tax fee increases know politicians straightforward terms economics hard hard call really customer huh agent silence customer see never thought really noise customer never really thought question really whether paying much little always thought real question getting reasonable return investment customer instance like social security tax soc ia ##l mean tax paying money supposedly money going kind fund comes turn retire money agent right laughter customer yeah know see money taken pay ##che ##ck week every week really think money history agent noise customer know far return investment nothing even going get exact number dollars back agent yes agent silence customer someone telling still office know staffed people researching find cure pol ##io customer silence customer may wrong believe cure pol ##io already founded supposedly office know staff people really tough close yet agent well yeah exactly sure pol ##io particular know pol ##io vaccine prevent [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] agent noise customer noise steve election year what ##not coming think ought cut taxes raise think agent silence agent well laughter really hard question know politicians always talking sides mouths customer silence agent noise let example friend president right says new taxes especially anything cutting taxes recession time budget sent congress agent tax fee increases know politicians straightforward terms economics hard hard call really customer huh agent silence customer see never thought really noise customer never really thought question really whether paying much little always thought real question getting reasonable return investment customer instance like social security tax soc ia ##l mean tax paying money supposedly money going kind fund comes turn retire money agent right laughter customer yeah know see money taken pay ##che ##ck week every week really think money history agent noise customer know far return investment nothing even going get exact number dollars back agent yes agent silence customer someone telling still office know staffed people researching find cure pol ##io customer silence customer may wrong believe cure pol ##io already founded supposedly office know staff people really tough close yet agent well yeah exactly sure pol ##io particular know pol ##io vaccine prevent [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 3889 2602 2095 2054 17048 2746 2228 11276 3013 7773 5333 2228 4005 4223 4005 2092 7239 2428 2524 3160 2113 8801 2467 3331 3903 15076 8013 4223 4005 5005 2292 2742 2767 2343 2157 2758 2047 7773 2926 2505 6276 7773 19396 2051 5166 2741 3519 4005 4171 7408 7457 2113 8801 19647 3408 5543 2524 2524 2655 2428 8013 9616 4005 4223 8013 2156 2196 2245 2428 5005 8013 2196 2428 2245 3160 2428 3251 7079 2172 2210 2467 2245 2613 3160 2893 9608 2709 5211 8013 6013 2066 2591 3036 4171 27084 24264 2140 2812 4171 7079 2769 10743 2769 2183 2785 4636 3310 2735 11036 2769 4005 2157 7239 8013 3398 2113 2156 2769 2579 3477 5403 3600 2733 2296 2733 2428 2228 2769 2381 4005 5005 8013 2113 2521 2709 5211 2498 2130 2183 2131 6635 2193 6363 2067 4005 2748 4005 4223 8013 2619 4129 2145 2436 2113 21121 2111 20059 2424 9526 14955 3695 8013 4223 8013 2089 3308 2903 9526 14955 3695 2525 2631 10743 2436 2113 3095 2111 2428 7823 2485 2664 4005 2092 3398 3599 2469 14955 3695 3327 2113 14955 3695 17404 4652 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4005 5005 8013 5005 3889 2602 2095 2054 17048 2746 2228 11276 3013 7773 5333 2228 4005 4223 4005 2092 7239 2428 2524 3160 2113 8801 2467 3331 3903 15076 8013 4223 4005 5005 2292 2742 2767 2343 2157 2758 2047 7773 2926 2505 6276 7773 19396 2051 5166 2741 3519 4005 4171 7408 7457 2113 8801 19647 3408 5543 2524 2524 2655 2428 8013 9616 4005 4223 8013 2156 2196 2245 2428 5005 8013 2196 2428 2245 3160 2428 3251 7079 2172 2210 2467 2245 2613 3160 2893 9608 2709 5211 8013 6013 2066 2591 3036 4171 27084 24264 2140 2812 4171 7079 2769 10743 2769 2183 2785 4636 3310 2735 11036 2769 4005 2157 7239 8013 3398 2113 2156 2769 2579 3477 5403 3600 2733 2296 2733 2428 2228 2769 2381 4005 5005 8013 2113 2521 2709 5211 2498 2130 2183 2131 6635 2193 6363 2067 4005 2748 4005 4223 8013 2619 4129 2145 2436 2113 21121 2111 20059 2424 9526 14955 3695 8013 4223 8013 2089 3308 2903 9526 14955 3695 2525 2631 10743 2436 2113 3095 2111 2428 7823 2485 2664 4005 2092 3398 3599 2469 14955 3695 3327 2113 14955 3695 17404 4652 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: Taxes (id = 5)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUPMThN3lNX"
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47PZZAtekBRT",
        "outputId": "af9cb188-ec59-40b0-db8e-e947856a7e36"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-03T11:35:28Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-03T11:35:28Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-03-11:35:52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-03-11:35:52\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 12: eval_accuracy = 0.5, false_negatives = 0.0, false_positives = 0.0, global_step = 12, loss = 1.5648428, true_negatives = 0.0, true_positives = 10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 12: eval_accuracy = 0.5, false_negatives = 0.0, false_positives = 0.0, global_step = 12, loss = 1.5648428, true_negatives = 0.0, true_positives = 10.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12: ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12: ./bert_conersation_tagging/model.ckpt-12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.5,\n",
              " 'false_negatives': 0.0,\n",
              " 'false_positives': 0.0,\n",
              " 'global_step': 12,\n",
              " 'loss': 1.5648428,\n",
              " 'true_negatives': 0.0,\n",
              " 'true_positives': 10.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Q52a9l9SjaCa",
        "outputId": "0b043535-bbf0-46ff-9625-94e7a48eb750"
      },
      "source": [
        "estimator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-7abd6375a45e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Estimator' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "OYW52tIN_kMZ",
        "outputId": "6c7466c9-132c-4953-8075-249bf38a54a5"
      },
      "source": [
        "modelPath = estimator.export_saved_model(\"./bert_conersation_tagging/model\", train_input_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-e25e98e211fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./bert_conersation_tagging/model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mexport_saved_model\u001b[0;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         strip_default_attrs=True)\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m   def experimental_export_all_saved_models(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_export_all_saved_models\u001b[0;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m           raise ValueError(\"Couldn't find trained model at {}.\".format(\n\u001b[0;32m--> 830\u001b[0;31m               self._model_dir))\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timestamped_export_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Couldn't find trained model at model."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "ma1IEZEE9E-k",
        "outputId": "15be4eb4-c242-4528-bc1d-94b95c9d9914"
      },
      "source": [
        "inputFn = tf.estimator.export.build_parsing_serving_input_receiver_fn(tf.feature_column.make_parse_example_spec(train_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-91914cca49ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputFn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_parsing_serving_input_receiver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_parse_example_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mmake_parse_example_spec\u001b[0;34m(feature_columns)\u001b[0m\n\u001b[1;32m    804\u001b[0m       raise ValueError(\n\u001b[1;32m    805\u001b[0m           \u001b[0;34m'All feature_columns must be _FeatureColumn instances. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m           'Given: {}'.format(column))\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_example_spec\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All feature_columns must be _FeatureColumn instances. Given: <run_classifier.InputFeatures object at 0x7fa711c3b2d0>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "c0DwwMgV9FET",
        "outputId": "9501d277-ffa9-4956-bdd2-0ce206ec4a71"
      },
      "source": [
        "estimator = tf.estimator.Estimator(model_fn, 'model', params={})\n",
        "estimator.export_saved_model('saved_model', serving_input_receiver_fn)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa713beba10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa713beba10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-ffd335d10dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_input_receiver_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mexport_saved_model\u001b[0;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         strip_default_attrs=True)\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m   def experimental_export_all_saved_models(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_export_all_saved_models\u001b[0;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m           raise ValueError(\"Couldn't find trained model at {}.\".format(\n\u001b[0;32m--> 830\u001b[0;31m               self._model_dir))\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_timestamped_export_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Couldn't find trained model at model."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83FrEOOd9FHe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmTFkPe9FKb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz6WyxUM9FNM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9BAxvT-9FQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TiwVPnSRV3L"
      },
      "source": [
        "dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnG1pDCTRV6U",
        "outputId": "7604705c-1a02-4d0d-ad37-6c93022cab1f"
      },
      "source": [
        "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaoaIi9wR2_S",
        "outputId": "51f137f6-46ec-4cc2-f3f6-e33738188724"
      },
      "source": [
        "max_len=1680\r\n",
        "sentences=data['file_content']\r\n",
        "labels=data['file_tag_encoder']\r\n",
        "len(sentences),len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7HkBJ2XR3Cc"
      },
      "source": [
        "dbert_tokenizer.tokenize(sentences[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IFnqw49R3Fq",
        "outputId": "15868ce8-eb33-4825-fcb7-195b4da79bff"
      },
      "source": [
        "dbert_inp=dbert_tokenizer.encode_plus(sentences[0],add_special_tokens = True,max_length =max_len,pad_to_max_length = True,truncation=True)\r\n",
        "dbert_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 4005, 4223, 8013, 2157, 4005, 3100, 8013, 2288, 2843, 7239, 2116, 4005, 4223, 4005, 2748, 7239, 2903, 3733, 2224, 8013, 4223, 8013, 3398, 2092, 3129, 2613, 2204, 2478, 4005, 4223, 4005, 7239, 2903, 3067, 2052, 2360, 4025, 11160, 2172, 8013, 4223, 8013, 4287, 7883, 3046, 2202, 2185, 4005, 4223, 4005, 7239, 8013, 4223, 4005, 5554, 3550, 5005, 2113, 4025, 2224, 5356, 2755, 2738, 4287, 5329, 2052, 5356, 8013, 3398, 2092, 2288, 3962, 4390, 2478, 4923, 5329, 3806, 4005, 4223, 4005, 2748, 8013, 2288, 4390, 4005, 4223, 4005, 2748, 2613, 3733, 3422, 8013, 4223, 8013, 7239, 3398, 4005, 2755, 3398, 7239, 3305, 3653, 14808, 24996, 8013, 4223, 4005, 4223, 4005, 4005, 4223, 4005, 2113, 2081, 3733, 7801, 2673, 4965, 8013, 27218, 6681, 4005, 4223, 4005, 2748, 8013, 4223, 8013, 2477, 4152, 4005, 4223, 4005, 4606, 2203, 17693, 4339, 8013, 4223, 4005, 4223, 8013, 2092, 4390, 2210, 7540, 3310, 27218, 3698, 7906, 7906, 7199, 11519, 2636, 4005, 9616, 4005, 4223, 4005, 2204, 8013, 4282, 15849, 11837, 5104, 4282, 15933, 16949, 4923, 4003, 7239, 2113, 2109, 4923, 4003, 3232, 2335, 3477, 8236, 4005, 4223, 4005, 7239, 4005, 4223, 4005, 3398, 2748, 4152, 13925, 4418, 8013, 4223, 4005, 4223, 8013, 3398, 4005, 2521, 2113, 7079, 5414, 2288, 4923, 4003, 3477, 5414, 8013, 4223, 8013, 3398, 3331, 4005, 4223, 4005, 8013, 4223, 4005, 3398, 27218, 3835, 2295, 2553, 2342, 2131, 4248, 5356, 2673, 2701, 8013, 3398, 2092, 3398, 2066, 6449, 2066, 4923, 5329, 2293, 7288, 3573, 4965, 2242, 7239, 4005, 4223, 4005, 2190, 2126, 7239, 7239, 2109, 7239, 7239, 7239, 7239, 2190, 7239, 2126, 7239, 2748, 2228, 4066, 8013, 4223, 4005, 2130, 2015, 2521, 5599, 4287, 2146, 4965, 2242, 8013, 3398, 4005, 7239, 8013, 2113, 2066, 7365, 2113, 2288, 2210, 5592, 3477, 4923, 7239, 7239, 7239, 7239, 2113, 2056, 12428, 2210, 4003, 4005, 4223, 4005, 7239, 4005, 4223, 4005, 2156, 20259, 3021, 2467, 3310, 2113, 2172, 3477, 8013, 4223, 4005, 4223, 8013, 3398, 2196, 2245, 2126, 2428, 2298, 7239, 3984, 11276, 2823, 4005, 7239, 4005, 2330, 2113, 3067, 2467, 5571, 4870, 2467, 2203, 3038, 2985, 2172, 2113, 3398, 8013, 4223, 8013, 2092, 2228, 2190, 2518, 4149, 10022, 4005, 4223, 4005, 8013, 4223, 4005, 4569, 8013, 3398, 4005, 2131, 2318, 8046, 8013, 4223, 8013, 2066, 4923, 5329, 7239, 2196, 2245, 2126, 2593, 2113, 23042, 2335, 4005, 7239, 3599, 4005, 7239, 4005, 4223, 4005, 2613, 3733, 2131, 23042, 2113, 2131, 6023, 3653, 2063, 21517, 3715, 4339, 4638, 2505, 8013, 4223, 8013, 2156, 2518, 2113, 5247, 4122, 2113, 4452, 4452, 2224, 4923, 4003, 4005, 4223, 8013, 4223, 4005, 3398, 3571, 2521, 6433, 8013, 3398, 2113, 2183, 14315, 9343, 2113, 4005, 4223, 8013, 14315, 2121, 2295, 4005, 7239, 8013, 12885, 2113, 2985, 4005, 4223, 4005, 3398, 8013, 4223, 4005, 4223, 8013, 7777, 4965, 4268, 10899, 5005, 4923, 4003, 2113, 24547, 20481, 2242, 4005, 3398, 4005, 4223, 4005, 3398, 11251, 8013, 4223, 4005, 2113, 2467, 2215, 2131, 4268, 2673, 2729, 2172, 5366, 3138, 8013, 3398, 2092, 4005, 4223, 8013, 2113, 8013, 4223, 8013, 24547, 20481, 8236, 4923, 4003, 4005, 9616, 8013, 4223, 4005, 4223, 4005, 3398, 2467, 2203, 2183, 24547, 20481, 5554, 3550, 5005, 2746, 2673, 2862, 4005, 2893, 2253, 7239, 8013, 7239, 2253, 4005, 4223, 8013, 2242, 2482, 2028, 2154, 2197, 2733, 2253, 2253, 4149, 8962, 3723, 3242, 2028, 14104, 16489, 2365, 2113, 8962, 3723, 3242, 2684, 4149, 4005, 9616, 4005, 4223, 4005, 7239, 4005, 4223, 4005, 7239, 4005, 4223, 8013, 3940, 6007, 2292, 2156, 2842, 4149, 3232, 7689, 6007, 4268, 2113, 2288, 2048, 4268, 4149, 6007, 8013, 4223, 4005, 3398, 4795, 8013, 7239, 7239, 7239, 2113, 2253, 2702, 7922, 3538, 2518, 2482, 3092, 8442, 10920, 6363, 24547, 20481, 2253, 3477, 3238, 4149, 6007, 4268, 7239, 4005, 4223, 4005, 14910, 3398, 3733, 2028, 2518, 14429, 8013, 4223, 4005, 8013, 3398, 2117, 4005, 4223, 4005, 7239, 8013, 4223, 4005, 2092, 3398, 2092, 5580, 4923, 5329, 4005, 2823, 5057, 3310, 18801, 8013, 3398, 4005, 3835, 8013, 2113, 2482, 3338, 2028, 2051, 4923, 4003, 5552, 4005, 4223, 4005, 3398, 8013, 4223, 4005, 4223, 4005, 3398, 4005, 5554, 3550, 5005, 5305, 4111, 4005, 29525, 2113, 3899, 29525, 6450, 4923, 4003, 3271, 2843, 2302, 8013, 2228, 2444, 4005, 4223, 4005, 9616, 2228, 2468, 2172, 10126, 2166, 2112, 8013, 4223, 8013, 3398, 2092, 4851, 3129, 4923, 5329, 2288, 2028, 4005, 4223, 4005, 7239, 8013, 4223, 4005, 4223, 8013, 5342, 2514, 4072, 4139, 4139, 7906, 2028, 4005, 7239, 8013, 7906, 2028, 2560, 3815, 2655, 3398, 4005, 4223, 4005, 5703, 4005, 4223, 8013, 4923, 2240, 2113, 4923, 5787, 2292, 2028, 2560, 3815, 4005, 2748, 9616, 4005, 4223, 8013, 4223, 4005, 2113, 5247, 2172, 8013, 3398, 2113, 2428, 3599, 3342, 2172, 2228, 2274, 3634, 5787, 2113, 2028, 15888, 4005, 4223, 4005, 2748, 14910, 8013, 4223, 4005, 4223, 8013, 2228, 2242, 2842, 8744, 4005, 4005, 4223, 8013, 4223, 4005, 2092, 2292, 2156, 3984, 5720, 2471, 2274, 2781, 8013, 2092, 2416, 2781, 2288, 25309, 4005, 4223, 4005, 8013, 5119, 3042, 4005, 4223, 4005, 4299, 2028, 8013, 2092, 4149, 4923, 7239, 2092, 2179, 14860, 9774, 3984, 4005, 4223, 4005, 7239, 2156, 7239, 7239, 7239, 4005, 4223, 8013, 10538, 4923, 4003, 18493, 7239, 4005, 9774, 8013, 2109, 3146, 4005, 3146, 3100, 2183, 15003, 2428, 2288, 2521, 8013, 4223, 8013, 2092, 4005, 4223, 8013, 2113, 2113, 2521, 3632, 4005, 3398, 3398, 5395, 8013, 3146, 8013, 4223, 4005, 4223, 8013, 11011, 11064, 2239, 2738, 4005, 3100, 3398, 14910, 8013, 4223, 4005, 2092, 2307, 2034, 2028, 8013, 2034, 3042, 2655, 2034, 2028, 4005, 9616, 4005, 4223, 8013, 4223, 4005, 3129, 2028, 2197, 2305, 3866, 4005, 2893, 2288, 2613, 2204, 8476, 8013, 9616, 4005, 4223, 8013, 4223, 4005, 2092, 4005, 4223, 8013, 2113, 2288, 2131, 2067, 4923, 5329, 7239, 4005, 3398, 2092, 2667, 2228, 2228, 3492, 2172, 2056, 8013, 4223, 8013, 5554, 3550, 5005, 4005, 8013, 4223, 4005, 3398, 2228, 2191, 2302, 8013, 2113, 2253, 4098, 2098, 3243, 2318, 2635, 4005, 4223, 8013, 5329, 2185, 4098, 2098, 2843, 2092, 2416, 2698, 4098, 2098, 4005, 14910, 8013, 4005, 4223, 8013, 2288, 2210, 2978, 4390, 2478, 2028, 3477, 8236, 2500, 2288, 4390, 4005, 7239, 4005, 3398, 3398, 8013, 4223, 4005, 3046, 2562, 4005, 4389, 7711, 4152, 2524, 2066, 2926, 2105, 4234, 2051, 5798, 2015, 8013, 9594, 3762, 4005, 4223, 8013, 2172, 2491, 3310, 2478, 4003, 7239, 2113, 4005, 7239, 4005, 4223, 8013, 3243, 2478, 8013, 2228, 2130, 2028, 2051, 2109, 3477, 9278, 4005, 15003, 8013, 2113, 4005, 4223, 8013, 2034, 2333, 2210, 2978, 4390, 2288, 6450, 2160, 4545, 2738, 2113, 2028, 2154, 4005, 9616, 4005, 4223, 4005, 9616, 4005, 4223, 8013, 2673, 17835, 18480, 2482, 2113, 2344, 2113, 5005, 7079, 4005, 4005, 4223, 8013, 9278, 20228, 2226, 3046, 13749, 4606, 2667, 2131, 2769, 2178, 2482, 4005, 4152, 5931, 8013, 2288, 2288, 2613, 5931, 4005, 2524, 8013, 10538, 3040, 4003, 4005, 4223, 4005, 2131, 5356, 5083, 9616, 8013, 4223, 8013, 3398, 2288, 2502, 5356, 5083, 2428, 3173, 2067, 4005, 7239, 4005, 4223, 8013, 4223, 4005, 3398, 2156, 2272, 18801, 4276, 4005, 4223, 4005, 2092, 2228, 3492, 2172, 2272, 2203, 8013, 3398, 2667, 2424, 2146, 4011, 2831, 4005, 4223, 4005, 2228, 2560, 2274, 2781, 8013, 4223, 8013, 2559, 2667, 2831, 2302, 2228, 3038, 2667, 2298, 2518, 4005, 4223, 4005, 7239, 4005, 4223, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItwtvXnYR3In"
      },
      "source": [
        "dbert_inp['input_ids']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "lG9oNhqqR3L2",
        "outputId": "9629ad7e-12a0-44c7-8632-4cd293eb8aea"
      },
      "source": [
        "id_inp=np.asarray(dbert_inp['input_ids'])\r\n",
        "mask_inp=np.asarray(dbert_inp['attention_mask'])\r\n",
        "out=dbert_model([id_inp.reshape(1,-1),mask_inp.reshape(1,-1)])\r\n",
        "type(out),out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-6d8f0d5d6058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mid_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbert_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmask_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbert_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_inp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_embeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         )  # (bs, seq_length, dim)\n\u001b[1;32m    487\u001b[0m         tfmr_output = self.transformer(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, training)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposition_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, position_ids)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(input, shape, name)\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       return broadcast_to_eager_fallback(\n\u001b[0;32m--> 832\u001b[0;31m           input, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    833\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mbroadcast_to_eager_fallback\u001b[0;34m(input, shape, name, ctx)\u001b[0m\n\u001b[1;32m    870\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m   _result = _execute.execute(b\"BroadcastTo\", 1, inputs=_inputs_flat,\n\u001b[0;32m--> 872\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    873\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [512,768] vs. [1,1680,768] [Op:BroadcastTo]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbLrqUCgR3O_"
      },
      "source": [
        "out[0][:,0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjtqfwWOR3Rd"
      },
      "source": [
        "dbert_tokenizer.decode(dbert_inp['input_ids'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieN9hpZDUqiP"
      },
      "source": [
        "num_classes=6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe02Jnw_R3U2"
      },
      "source": [
        "def create_model():\r\n",
        "    inps = Input(shape = (max_len,), dtype='int64')\r\n",
        "    masks= Input(shape = (max_len,), dtype='int64')\r\n",
        "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\r\n",
        "    dense = Dense(1680,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\r\n",
        "    dropout= Dropout(0.5)(dense)\r\n",
        "    pred = Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\r\n",
        "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\r\n",
        "    print(model.summary())\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "U7mHIe3CR3XF",
        "outputId": "ef16fce4-dd75-4bbb-b84d-15c6aa142fa5"
      },
      "source": [
        "model=create_model()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e4a87514d571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-6e72d30081b6>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdbert_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1680\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbert_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:645 call  *\n        outputs = self.distilbert(\n    /usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:484 call  *\n        embedding_output = self.embeddings(\n    /usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:184 call  *\n        position_embeds = self.position_embeddings(position_ids=inputs_embeds)\n    /usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_tf_distilbert.py:143 call  *\n        return tf.broadcast_to(input=position_embeddings, shape=input_shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:845 broadcast_to  **\n        \"BroadcastTo\", input=input, shape=shape, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 512 and 1680 for '{{node tf_distil_bert_model_1/distilbert/embeddings/position_embeddings/BroadcastTo}} = BroadcastTo[T=DT_FLOAT, Tidx=DT_INT32](tf_distil_bert_model_1/distilbert/embeddings/position_embeddings/strided_slice_1, tf_distil_bert_model_1/distilbert/embeddings/position_embeddings/BroadcastTo/shape)' with input shapes: [512,768], [3] and with input tensors computed as partial shapes: input[1] = [?,1680,768].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jedagcWWR3aS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOYH2QtGRV-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAnpjvtMaV4T"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import copy\r\n",
        "import numpy as np\r\n",
        "import imgaug as ia\r\n",
        "from imgaug import augmenters as iaa\r\n",
        "from keras.utils import Sequence\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "\r\n",
        "def parse_annotation(ann_dir, img_dir, labels=[]):\r\n",
        "    all_imgs = []\r\n",
        "    seen_labels = {}\r\n",
        "    \r\n",
        "    for ann in sorted(os.listdir(ann_dir)):\r\n",
        "        img = {'object':[]}\r\n",
        "\r\n",
        "        tree = ET.parse(ann_dir + ann)\r\n",
        "        \r\n",
        "        for elem in tree.iter():\r\n",
        "            if 'filename' in elem.tag:\r\n",
        "                img['filename'] = img_dir + elem.text\r\n",
        "            if 'width' in elem.tag:\r\n",
        "                img['width'] = int(elem.text)\r\n",
        "            if 'height' in elem.tag:\r\n",
        "                img['height'] = int(elem.text)\r\n",
        "            if 'object' in elem.tag or 'part' in elem.tag:\r\n",
        "                obj = {}\r\n",
        "                \r\n",
        "                for attr in list(elem):\r\n",
        "                    if 'name' in attr.tag:\r\n",
        "                        obj['name'] = attr.text\r\n",
        "\r\n",
        "                        if obj['name'] in seen_labels:\r\n",
        "                            seen_labels[obj['name']] += 1\r\n",
        "                        else:\r\n",
        "                            seen_labels[obj['name']] = 1\r\n",
        "                        \r\n",
        "                        if len(labels) > 0 and obj['name'] not in labels:\r\n",
        "                            break\r\n",
        "                        else:\r\n",
        "                            img['object'] += [obj]\r\n",
        "                            \r\n",
        "                    if 'bndbox' in attr.tag:\r\n",
        "                        for dim in list(attr):\r\n",
        "                            if 'xmin' in dim.tag:\r\n",
        "                                obj['xmin'] = int(round(float(dim.text)))\r\n",
        "                            if 'ymin' in dim.tag:\r\n",
        "                                obj['ymin'] = int(round(float(dim.text)))\r\n",
        "                            if 'xmax' in dim.tag:\r\n",
        "                                obj['xmax'] = int(round(float(dim.text)))\r\n",
        "                            if 'ymax' in dim.tag:\r\n",
        "                                obj['ymax'] = int(round(float(dim.text)))\r\n",
        "\r\n",
        "        if len(img['object']) > 0:\r\n",
        "            all_imgs += [img]\r\n",
        "                        \r\n",
        "    return all_imgs, seen_labels\r\n",
        "\r\n",
        "class BatchGenerator(Sequence):\r\n",
        "    def __init__(self, images, \r\n",
        "                       config, \r\n",
        "                       shuffle=True, \r\n",
        "                       jitter=True, \r\n",
        "                       norm=None):\r\n",
        "        self.generator = None\r\n",
        "\r\n",
        "        self.images = images\r\n",
        "        self.config = config\r\n",
        "\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.jitter  = jitter\r\n",
        "        self.norm    = norm\r\n",
        "\r\n",
        "        self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\r\n",
        "\r\n",
        "        ### augmentors by https://github.com/aleju/imgaug\r\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\r\n",
        "\r\n",
        "        # Define our sequence of augmentation steps that will be applied to every image\r\n",
        "        # All augmenters with per_channel=0.5 will sample one value _per image_\r\n",
        "        # in 50% of all cases. In all other cases they will sample new values\r\n",
        "        # _per channel_.\r\n",
        "        self.aug_pipe = iaa.Sequential(\r\n",
        "            [\r\n",
        "                # apply the following augmenters to most images\r\n",
        "                #iaa.Fliplr(0.5), # horizontally flip 50% of all images\r\n",
        "                #iaa.Flipud(0.2), # vertically flip 20% of all images\r\n",
        "                #sometimes(iaa.Crop(percent=(0, 0.1))), # crop images by 0-10% of their height/width\r\n",
        "                sometimes(iaa.Affine(\r\n",
        "                    #scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\r\n",
        "                    #translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\r\n",
        "                    #rotate=(-5, 5), # rotate by -45 to +45 degrees\r\n",
        "                    #shear=(-5, 5), # shear by -16 to +16 degrees\r\n",
        "                    #order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\r\n",
        "                    #cval=(0, 255), # if mode is constant, use a cval between 0 and 255\r\n",
        "                    #mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\r\n",
        "                )),\r\n",
        "                # execute 0 to 5 of the following (less important) augmenters per image\r\n",
        "                # don't execute all of them, as that would often be way too strong\r\n",
        "                iaa.SomeOf((0, 5),\r\n",
        "                    [\r\n",
        "                        #sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\r\n",
        "                        iaa.OneOf([\r\n",
        "                            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\r\n",
        "                            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\r\n",
        "                            iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\r\n",
        "                        ]),\r\n",
        "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\r\n",
        "                        #iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\r\n",
        "                        # search either for all edges or for directed edges\r\n",
        "                        #sometimes(iaa.OneOf([\r\n",
        "                        #    iaa.EdgeDetect(alpha=(0, 0.7)),\r\n",
        "                        #    iaa.DirectedEdgeDetect(alpha=(0, 0.7), direction=(0.0, 1.0)),\r\n",
        "                        #])),\r\n",
        "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\r\n",
        "                        iaa.OneOf([\r\n",
        "                            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\r\n",
        "                            #iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\r\n",
        "                        ]),\r\n",
        "                        #iaa.Invert(0.05, per_channel=True), # invert color channels\r\n",
        "                        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\r\n",
        "                        iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\r\n",
        "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\r\n",
        "                        #iaa.Grayscale(alpha=(0.0, 1.0)),\r\n",
        "                        #sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\r\n",
        "                        #sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))) # sometimes move parts of the image around\r\n",
        "                    ],\r\n",
        "                    random_order=True\r\n",
        "                )\r\n",
        "            ],\r\n",
        "            random_order=True\r\n",
        "        )\r\n",
        "\r\n",
        "        if shuffle: np.random.shuffle(self.images)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))   \r\n",
        "\r\n",
        "    def num_classes(self):\r\n",
        "        return len(self.config['LABELS'])\r\n",
        "\r\n",
        "    def size(self):\r\n",
        "        return len(self.images)    \r\n",
        "\r\n",
        "    def load_annotation(self, i):\r\n",
        "        annots = []\r\n",
        "\r\n",
        "        for obj in self.images[i]['object']:\r\n",
        "            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\r\n",
        "            annots += [annot]\r\n",
        "\r\n",
        "        if len(annots) == 0: annots = [[]]\r\n",
        "\r\n",
        "        return np.array(annots)\r\n",
        "\r\n",
        "    def load_image(self, i):\r\n",
        "        return cv2.imread(self.images[i]['filename'])\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        l_bound = idx*self.config['BATCH_SIZE']\r\n",
        "        r_bound = (idx+1)*self.config['BATCH_SIZE']\r\n",
        "\r\n",
        "        if r_bound > len(self.images):\r\n",
        "            r_bound = len(self.images)\r\n",
        "            l_bound = r_bound - self.config['BATCH_SIZE']\r\n",
        "\r\n",
        "        instance_count = 0\r\n",
        "\r\n",
        "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\r\n",
        "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\r\n",
        "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\r\n",
        "\r\n",
        "        for train_instance in self.images[l_bound:r_bound]:\r\n",
        "            # augment input image and fix object's position and size\r\n",
        "            img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\r\n",
        "            \r\n",
        "            # construct output from object's x, y, w, h\r\n",
        "            true_box_index = 0\r\n",
        "            \r\n",
        "            for obj in all_objs:\r\n",
        "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\r\n",
        "                    center_x = .5*(obj['xmin'] + obj['xmax'])\r\n",
        "                    center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\r\n",
        "                    center_y = .5*(obj['ymin'] + obj['ymax'])\r\n",
        "                    center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\r\n",
        "\r\n",
        "                    grid_x = int(np.floor(center_x))\r\n",
        "                    grid_y = int(np.floor(center_y))\r\n",
        "\r\n",
        "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\r\n",
        "                        obj_indx  = self.config['LABELS'].index(obj['name'])\r\n",
        "                        \r\n",
        "                        center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W']) # unit: grid cell\r\n",
        "                        center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\r\n",
        "                        \r\n",
        "                        box = [center_x, center_y, center_w, center_h]\r\n",
        "\r\n",
        "                        # find the anchor that best predicts this box\r\n",
        "                        best_anchor = -1\r\n",
        "                        max_iou     = -1\r\n",
        "                        \r\n",
        "                        shifted_box = BoundBox(0, \r\n",
        "                                               0,\r\n",
        "                                               center_w,                                                \r\n",
        "                                               center_h)\r\n",
        "                        \r\n",
        "                        for i in range(len(self.anchors)):\r\n",
        "                            anchor = self.anchors[i]\r\n",
        "                            iou    = bbox_iou(shifted_box, anchor)\r\n",
        "                            \r\n",
        "                            if max_iou < iou:\r\n",
        "                                best_anchor = i\r\n",
        "                                max_iou     = iou\r\n",
        "                                \r\n",
        "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\r\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\r\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\r\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\r\n",
        "                        \r\n",
        "                        # assign the true box to b_batch\r\n",
        "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\r\n",
        "                        \r\n",
        "                        true_box_index += 1\r\n",
        "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\r\n",
        "                            \r\n",
        "            # assign input image to x_batch\r\n",
        "            if self.norm != None: \r\n",
        "                x_batch[instance_count] = self.norm(img)\r\n",
        "            else:\r\n",
        "                # plot image and bounding boxes for sanity check\r\n",
        "                for obj in all_objs:\r\n",
        "                    if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\r\n",
        "                        cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\r\n",
        "                        cv2.putText(img[:,:,::-1], obj['name'], \r\n",
        "                                    (obj['xmin']+2, obj['ymin']+12), \r\n",
        "                                    0, 1.2e-3 * img.shape[0], \r\n",
        "                                    (0,255,0), 2)\r\n",
        "                        \r\n",
        "                x_batch[instance_count] = img\r\n",
        "\r\n",
        "            # increase instance counter in current batch\r\n",
        "            instance_count += 1  \r\n",
        "\r\n",
        "        #print(' new batch created', idx)\r\n",
        "\r\n",
        "        return [x_batch, b_batch], y_batch\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        if self.shuffle: np.random.shuffle(self.images)\r\n",
        "\r\n",
        "    def aug_image(self, train_instance, jitter):\r\n",
        "        image_name = train_instance['filename']\r\n",
        "        image = cv2.imread(image_name)\r\n",
        "\r\n",
        "        if image is None: print('Cannot find ', image_name)\r\n",
        "\r\n",
        "        h, w, c = image.shape\r\n",
        "        all_objs = copy.deepcopy(train_instance['object'])\r\n",
        "\r\n",
        "        if jitter:\r\n",
        "            ### scale the image\r\n",
        "            scale = np.random.uniform() / 10. + 1.\r\n",
        "            image = cv2.resize(image, (0,0), fx = scale, fy = scale)\r\n",
        "\r\n",
        "            ### translate the image\r\n",
        "            max_offx = (scale-1.) * w\r\n",
        "            max_offy = (scale-1.) * h\r\n",
        "            offx = int(np.random.uniform() * max_offx)\r\n",
        "            offy = int(np.random.uniform() * max_offy)\r\n",
        "            \r\n",
        "            image = image[offy : (offy + h), offx : (offx + w)]\r\n",
        "\r\n",
        "            ### flip the image\r\n",
        "            flip = np.random.binomial(1, .5)\r\n",
        "            if flip > 0.5: image = cv2.flip(image, 1)\r\n",
        "                \r\n",
        "            image = self.aug_pipe.augment_image(image)            \r\n",
        "            \r\n",
        "        # resize the image to standard size\r\n",
        "        image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\r\n",
        "        image = image[:,:,::-1]\r\n",
        "\r\n",
        "        # fix object's position and size\r\n",
        "        for obj in all_objs:\r\n",
        "            for attr in ['xmin', 'xmax']:\r\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offx)\r\n",
        "                    \r\n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\r\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\r\n",
        "                \r\n",
        "            for attr in ['ymin', 'ymax']:\r\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offy)\r\n",
        "                    \r\n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\r\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\r\n",
        "\r\n",
        "            if jitter and flip > 0.5:\r\n",
        "                xmin = obj['xmin']\r\n",
        "                obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\r\n",
        "                obj['xmax'] = self.config['IMAGE_W'] - xmin\r\n",
        "                \r\n",
        "        return image, all_objs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OBoe4C9cDNc"
      },
      "source": [
        "LABELS = ['mask','no_mask']\r\n",
        "IMAGE_H, IMAGE_W = 416, 416\r\n",
        "GRID_H,  GRID_W  = 13 , 13\r\n",
        "BOX              = 5\r\n",
        "CLASS            = len(LABELS)\r\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\r\n",
        "OBJ_THRESHOLD    = 0.3#0.5\r\n",
        "NMS_THRESHOLD    = 0.3#0.45\r\n",
        "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\r\n",
        "\r\n",
        "NO_OBJECT_SCALE  = 1.0\r\n",
        "OBJECT_SCALE     = 5.0\r\n",
        "COORD_SCALE      = 1.0\r\n",
        "CLASS_SCALE      = 1.0\r\n",
        "\r\n",
        "BATCH_SIZE       = 16\r\n",
        "WARM_UP_BATCHES  = 0\r\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxw88EB9cDW4"
      },
      "source": [
        "wt_path = '/content/drive/My Drive/Colab Notebooks/yolov2.weights'                      \r\n",
        "train_image_folder = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/'\r\n",
        "train_annot_folder = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_xmls_test/'\r\n",
        "valid_image_folder = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/valid_images_test/'\r\n",
        "valid_annot_folder = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/valid_xmls_test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wflQZVoPcDac"
      },
      "source": [
        "def space_to_depth_x2(x):\r\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HHanTVAcDhB",
        "outputId": "eb529007-0f07-4cb3-f960-2ec9c89f875e"
      },
      "source": [
        "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\r\n",
        "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\r\n",
        "\r\n",
        "# Layer 1\r\n",
        "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\r\n",
        "x = BatchNormalization(name='norm_1')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\r\n",
        "# Layer 2\r\n",
        "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_2')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\r\n",
        "# Layer 3\r\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_3')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 4\r\n",
        "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_4')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 5\r\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_5')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\r\n",
        "# Layer 6\r\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_6')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 7\r\n",
        "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_7')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 8\r\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_8')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\r\n",
        "# Layer 9\r\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_9')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 10\r\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_10')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 11\r\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_11')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 12\r\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_12')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 13\r\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_13')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "skip_connection = x\r\n",
        "\r\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\r\n",
        "# Layer 14\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_14')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 15\r\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_15')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 16\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_16')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 17\r\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_17')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 18\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_18')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 19\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_19')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 20\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_20')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 21\r\n",
        "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\r\n",
        "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\r\n",
        "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\r\n",
        "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\r\n",
        "\r\n",
        "x = concatenate([skip_connection, x])\r\n",
        "\r\n",
        "# Layer 22\r\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\r\n",
        "x = BatchNormalization(name='norm_22')(x)\r\n",
        "x = LeakyReLU(alpha=0.1)(x)\r\n",
        "\r\n",
        "# Layer 23\r\n",
        "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\r\n",
        "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\r\n",
        "\r\n",
        "# small hack to allow true_boxes to be registered when Keras build the model \r\n",
        "# for more information: https://github.com/fchollet/keras/issues/2790\r\n",
        "output = Lambda(lambda args: args[0])([output, true_boxes])\r\n",
        "\r\n",
        "model = Model([input_image, true_boxes], output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6_cCb9vcDkd",
        "outputId": "3edf46af-f04e-432f-bb38-1865de888836"
      },
      "source": [
        "model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 128 0           norm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           norm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 13, 13, 1280) 0           lambda_1[0][0]                   \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_23 (Conv2D)                (None, 13, 13, 35)   35875       leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 13, 13, 5, 7) 0           conv_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1, 1, 1, 50,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 13, 13, 5, 7) 0           reshape_1[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,583,811\n",
            "Trainable params: 50,563,139\n",
            "Non-trainable params: 20,672\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NH6rpn1aV7L"
      },
      "source": [
        "weight_reader = WeightReader(wt_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RjLptSsaV-a"
      },
      "source": [
        "weight_reader.reset()\r\n",
        "nb_conv = 23\r\n",
        "\r\n",
        "for i in range(1, nb_conv+1):\r\n",
        "    conv_layer = model.get_layer('conv_' + str(i))\r\n",
        "    \r\n",
        "    if i < nb_conv:\r\n",
        "        norm_layer = model.get_layer('norm_' + str(i))\r\n",
        "        \r\n",
        "        size = np.prod(norm_layer.get_weights()[0].shape)\r\n",
        "\r\n",
        "        beta  = weight_reader.read_bytes(size)\r\n",
        "        gamma = weight_reader.read_bytes(size)\r\n",
        "        mean  = weight_reader.read_bytes(size)\r\n",
        "        var   = weight_reader.read_bytes(size)\r\n",
        "\r\n",
        "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \r\n",
        "        \r\n",
        "    if len(conv_layer.get_weights()) > 1:\r\n",
        "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\r\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "        kernel = kernel.transpose([2,3,1,0])\r\n",
        "        conv_layer.set_weights([kernel, bias])\r\n",
        "    else:\r\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "        kernel = kernel.transpose([2,3,1,0])\r\n",
        "        conv_layer.set_weights([kernel])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEl_mzfaWBy"
      },
      "source": [
        "layer   = model.layers[-4] # the last convolutional layer\r\n",
        "weights = layer.get_weights()\r\n",
        "\r\n",
        "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\r\n",
        "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\r\n",
        "\r\n",
        "layer.set_weights([new_kernel, new_bias])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjCF5yVOyvVN"
      },
      "source": [
        "def custom_loss(y_true, y_pred):\r\n",
        "    mask_shape = tf.shape(y_true)[:4]\r\n",
        "    \r\n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\r\n",
        "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\r\n",
        "\r\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\r\n",
        "    \r\n",
        "    coord_mask = tf.zeros(mask_shape)\r\n",
        "    conf_mask  = tf.zeros(mask_shape)\r\n",
        "    class_mask = tf.zeros(mask_shape)\r\n",
        "    \r\n",
        "    seen = tf.Variable(0.)\r\n",
        "    total_recall = tf.Variable(0.)\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    Adjust prediction\r\n",
        "    \"\"\"\r\n",
        "    ### adjust x and y      \r\n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\r\n",
        "    \r\n",
        "    ### adjust w and h\r\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\r\n",
        "    \r\n",
        "    ### adjust confidence\r\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\r\n",
        "    \r\n",
        "    ### adjust class probabilities\r\n",
        "    pred_box_class = y_pred[..., 5:]\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    Adjust ground truth\r\n",
        "    \"\"\"\r\n",
        "    ### adjust x and y\r\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\r\n",
        "    \r\n",
        "    ### adjust w and h\r\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\r\n",
        "    \r\n",
        "    ### adjust confidence\r\n",
        "    true_wh_half = true_box_wh / 2.\r\n",
        "    true_mins    = true_box_xy - true_wh_half\r\n",
        "    true_maxes   = true_box_xy + true_wh_half\r\n",
        "    \r\n",
        "    pred_wh_half = pred_box_wh / 2.\r\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\r\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \r\n",
        "    \r\n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\r\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\r\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\r\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n",
        "    \r\n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\r\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\r\n",
        "\r\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\r\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\r\n",
        "    \r\n",
        "    true_box_conf = iou_scores * y_true[..., 4]\r\n",
        "    \r\n",
        "    ### adjust class probabilities\r\n",
        "    true_box_class = tf.argmax(y_true[..., 5:], -1)\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    Determine the masks\r\n",
        "    \"\"\"\r\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\r\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\r\n",
        "    \r\n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\r\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\r\n",
        "    true_xy = true_boxes[..., 0:2]\r\n",
        "    true_wh = true_boxes[..., 2:4]\r\n",
        "    \r\n",
        "    true_wh_half = true_wh / 2.\r\n",
        "    true_mins    = true_xy - true_wh_half\r\n",
        "    true_maxes   = true_xy + true_wh_half\r\n",
        "    \r\n",
        "    pred_xy = tf.expand_dims(pred_box_xy, 4)\r\n",
        "    pred_wh = tf.expand_dims(pred_box_wh, 4)\r\n",
        "    \r\n",
        "    pred_wh_half = pred_wh / 2.\r\n",
        "    pred_mins    = pred_xy - pred_wh_half\r\n",
        "    pred_maxes   = pred_xy + pred_wh_half    \r\n",
        "    \r\n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\r\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\r\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\r\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\r\n",
        "    \r\n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\r\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\r\n",
        "\r\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\r\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\r\n",
        "\r\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=4)\r\n",
        "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\r\n",
        "    \r\n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\r\n",
        "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\r\n",
        "    \r\n",
        "    ### class mask: simply the position of the ground truth boxes (the predictors)\r\n",
        "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    Warm-up training\r\n",
        "    \"\"\"\r\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\r\n",
        "    seen = tf.assign_add(seen, 1.)\r\n",
        "    \r\n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \r\n",
        "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \r\n",
        "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \r\n",
        "                                   tf.ones_like(coord_mask)],\r\n",
        "                          lambda: [true_box_xy, \r\n",
        "                                   true_box_wh,\r\n",
        "                                   coord_mask])\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    Finalize the loss\r\n",
        "    \"\"\"\r\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\r\n",
        "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\r\n",
        "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\r\n",
        "    \r\n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\r\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\r\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\r\n",
        "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\r\n",
        "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\r\n",
        "    \r\n",
        "    loss = loss_xy + loss_wh + loss_conf + loss_class\r\n",
        "    \r\n",
        "    nb_true_box = tf.reduce_sum(y_true[..., 4])\r\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Debugging code\r\n",
        "    \"\"\"    \r\n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\r\n",
        "    total_recall = tf.assign_add(total_recall, current_recall) \r\n",
        "\r\n",
        "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\r\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\r\n",
        "    \r\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1y8uApyvYJ"
      },
      "source": [
        "generator_config = {\r\n",
        "    'IMAGE_H'         : IMAGE_H, \r\n",
        "    'IMAGE_W'         : IMAGE_W,\r\n",
        "    'GRID_H'          : GRID_H,  \r\n",
        "    'GRID_W'          : GRID_W,\r\n",
        "    'BOX'             : BOX,\r\n",
        "    'LABELS'          : LABELS,\r\n",
        "    'CLASS'           : len(LABELS),\r\n",
        "    'ANCHORS'         : ANCHORS,\r\n",
        "    'BATCH_SIZE'      : BATCH_SIZE,\r\n",
        "    'TRUE_BOX_BUFFER' : 50,\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K22gXtKlyvd2"
      },
      "source": [
        "def normalize(image):\r\n",
        "    return image / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUidoQaQzAb4"
      },
      "source": [
        "train_imgs, seen_train_labels = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\r\n",
        "### write parsed annotations to pickle for fast retrieval next time\r\n",
        "#with open('train_imgs', 'wb') as fp:\r\n",
        "#    pickle.dump(train_imgs, fp)\r\n",
        "\r\n",
        "### read saved pickle of parsed annotations\r\n",
        "#with open ('train_imgs', 'rb') as fp:\r\n",
        "#    train_imgs = pickle.load(fp)\r\n",
        "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\r\n",
        "\r\n",
        "valid_imgs, seen_valid_labels = parse_annotation(valid_annot_folder, valid_image_folder, labels=LABELS)\r\n",
        "### write parsed annotations to pickle for fast retrieval next time\r\n",
        "#with open('valid_imgs', 'wb') as fp:\r\n",
        "#    pickle.dump(valid_imgs, fp)\r\n",
        "\r\n",
        "### read saved pickle of parsed annotations\r\n",
        "#with open ('valid_imgs', 'rb') as fp:\r\n",
        "#    valid_imgs = pickle.load(fp)\r\n",
        "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3N0fbL5zAfM"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', \r\n",
        "                           min_delta=0.001, \r\n",
        "                           patience=3, \r\n",
        "                           mode='min', \r\n",
        "                           verbose=1)\r\n",
        "\r\n",
        "checkpoint = ModelCheckpoint('yolov2_face_mask_weights.h5', \r\n",
        "                             monitor='val_loss', \r\n",
        "                             verbose=1, \r\n",
        "                             save_best_only=True, \r\n",
        "                             mode='min', \r\n",
        "                             period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93VIMr-z0saU"
      },
      "source": [
        "! mkdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FxOn-j8-0wxT",
        "outputId": "dce5c046-f9d5-4047-d97b-d7e2e14320f3"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mzry8WDyvhO",
        "outputId": "76187530-b892-40f5-cb45-39ba35f28980"
      },
      "source": [
        "tb_counter  = len([log for log in os.listdir(os.path.expanduser('/content/drive/My Drive/logs/')) if 'coco_' in log]) + 1\r\n",
        "tensorboard = TensorBoard(log_dir=os.path.expanduser('/content/drive/My Drive/logs/') + 'coco_' + '_' + str(tb_counter), \r\n",
        "                          histogram_freq=0, \r\n",
        "                          write_graph=True, \r\n",
        "                          write_images=False)\r\n",
        "\r\n",
        "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\r\n",
        "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\r\n",
        "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\r\n",
        "\r\n",
        "model.compile(loss=custom_loss, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-1c1e9c0c2ea6>:4: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From <ipython-input-15-1c1e9c0c2ea6>:145: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
            "Instructions for updating:\n",
            "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
            "```python\n",
            "    sess = tf.compat.v1.Session()\n",
            "    with sess.as_default():\n",
            "        tensor = tf.range(10)\n",
            "        print_op = tf.print(tensor)\n",
            "        with tf.control_dependencies([print_op]):\n",
            "          out = tf.add(tensor, tensor)\n",
            "        sess.run(out)\n",
            "    ```\n",
            "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
            "the following:\n",
            "\n",
            "  `from __future__ import print_function`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMB-ifkHaWFY",
        "outputId": "985606d2-9318-4853-8c71-1fdb58acae56"
      },
      "source": [
        "model.fit_generator(generator        = train_batch, \r\n",
        "                    steps_per_epoch  = len(train_batch), \r\n",
        "                    epochs           = 10, \r\n",
        "                    verbose          = 1,\r\n",
        "                    validation_data  = valid_batch,\r\n",
        "                    validation_steps = len(valid_batch),\r\n",
        "                    callbacks        = [early_stop, checkpoint, tensorboard], \r\n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "43/43 [==============================] - 2182s 51s/step - loss: 1.0017 - val_loss: 0.9744\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.97437, saving model to yolov2_face_mask_weights.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 2213s 51s/step - loss: 0.7001 - val_loss: 0.9504\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.97437 to 0.95037, saving model to yolov2_face_mask_weights.h5\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 2356s 55s/step - loss: 0.5580 - val_loss: 0.4924\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.95037 to 0.49240, saving model to yolov2_face_mask_weights.h5\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 2188s 51s/step - loss: 0.4509 - val_loss: 0.5186\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.49240\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 2195s 51s/step - loss: 0.3793 - val_loss: 0.5673\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.49240\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 2342s 54s/step - loss: 0.3556 - val_loss: 0.5197\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.49240\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff3f6044400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvJN_lQzzRgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcnYZuROzRjQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoalPOSWzRqq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kASGnQlQ9bXS"
      },
      "source": [
        "os.chdir('Colab Notebooks/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx1AwY5MvHAW",
        "outputId": "3e029abc-92fb-457e-ca27-186f41daa892"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of data_on_all_incidents.ipynb'\n",
            "'Copy of Lstm_Attention_textclassification.ipynb'\n",
            "'Copy of mmw_cnn1d_colab.ipynb'\n",
            "'Copy of Snippets: Importing libraries'\n",
            "'Copy of Untitled1.ipynb'\n",
            "'Copy of with_mix_2018_data (1).ipynb'\n",
            "'Copy of with_mix_2018_data.ipynb'\n",
            " data_on_all_incidents.ipynb\n",
            "'facing_problem_loding_lstm _attention.ipynb'\n",
            " geanie\n",
            " Glove_with_mix_2018_data.ipynb\n",
            " images-20210217T050756Z-001\n",
            " Itera_3_with_mix_2018_data.ipynb\n",
            " Lstm_Attention_textclassification.ipynb\n",
            " Lstm_Attention_textclassification_nehru.ipynb\n",
            " Mean_W2VEC_with_mix_2018_data.ipynb\n",
            " mmw_cnn1d_colab.ipynb\n",
            " processed_images.zip\n",
            " test_on_data_on_all_incidents.ipynb\n",
            " TFIDF_W2VEC_with_mix_2018_data.ipynb\n",
            " TF_object_detection.ipynb\n",
            " Top_cis_gt_1000.ipynb\n",
            " Top_cis_lt_1000.ipynb\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            " Untitled4.ipynb\n",
            " Untitled5.ipynb\n",
            " Untitled6.ipynb\n",
            " util1.ipynb\n",
            " Yolo_v2_face_mask_detection.ipynb\n",
            " yolov2-voc.weights\n",
            " yolov2.weights\n",
            " yolo-v4-tf.keras\n",
            " yolo-v4-tf.keras.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXOOLbzm_a4P"
      },
      "source": [
        "os.chdir('yolo-v4-tf.keras/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNj8Zosu_tcj"
      },
      "source": [
        "os.chdir('notebook/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWmXNemJ_tg1"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJCCH9Mf_3KN"
      },
      "source": [
        "from utils import DataGenerator, read_annotation_lines\n",
        "from models import Yolov4\n",
        "from config import yolo_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G0AV8Yt_3UP"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-YR7lq_8Kv",
        "outputId": "f92e5851-172a-49ce-b82e-56ebf5b64476"
      },
      "source": [
        "train_lines, val_lines = read_annotation_lines('/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_txt_annotattions/annotations-test.txt', test_size=0.1)\n",
        "FOLDER_PATH = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/'\n",
        "class_name_path = '/content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/classes.txt'\n",
        "data_gen_train = DataGenerator(train_lines, class_name_path, FOLDER_PATH)\n",
        "data_gen_val = DataGenerator(val_lines, class_name_path, FOLDER_PATH)\n",
        "\n",
        "model = Yolov4(weight_path='../yolo4_weight.h5',class_name_path=class_name_path)\n",
        "\n",
        "model_file = \"./Yolov4_test_mask.h5\"\n",
        "model_cp = tf.keras.callbacks.ModelCheckpoint(filepath=model_file, verbose=1, save_best_only=True, save_weights_only=False)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nms iou: 0.413 score: 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iPjZpIxB_8PW",
        "outputId": "99ad65ad-9dbf-4088-dec5-8372c73e3a49"
      },
      "source": [
        "model.fit(data_gen_train, \n",
        "          initial_epoch=0,\n",
        "          epochs=1, \n",
        "          val_data_gen=data_gen_val,\n",
        "          callbacks=[model_cp,reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 27nt02wuhan5_1580094096.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 4dbab3160b74425bbcccbfb544c4bd2f.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path hbghxdx.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1948261-1595163312.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path China-coronavirus-AP-1024x576.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 4646.png\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 389711_84767ea8af93d57a_o.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path china-coronavirus.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5c11f9e82400006d049a0ed8.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200123-775466925_wh_3925_bbe34a4d968d0381926b2ff40423ce24_custom-8a29adeb65fa41f5a851f0ddc73843e4be5376f8-s800-c85.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path image1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path d6c103ca-7ec5-450f-9243-27663bcb4deb_0.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 29xp-mask-mediumSquareAt3X.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1580571207_88208.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path https___s3-ap-northeast-1.amazonaws.com_psh-ex-ftnikkei-3937bb4_images_2_8_5_1_24761582-1-eng-GB_bangkok.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200131-coronavirus-quiapo-manila-jc-1674.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 783be4c62f564a17ab5c260b0488296e.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path At-bus-stop-6-44-9-waiting.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1200x818.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path busstop.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200128001360.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20171106_T0207-1024x623.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path -I1-MS09uaqsLdGTFkgnS0Rcg1mmPyAj95ySg_eckoM.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 304a4d44504b364d646b.jpg\n",
            " 1/78 [..............................] - ETA: 59:25 - loss: 122485.6875self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coverC.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200128150215888112.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1580193665-6e1d2548b55cbedaec4223d1180459e2.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 135e-huxwryw6451820.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 200128110635-02-wuhan-virus-beijing-0127-super-tease.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e476cd4cd34a.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020013023283369938.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path China_teens.0.jpg\n",
            " 2/78 [..............................] - ETA: 37:11 - loss: 123521.9102self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1125506397_15801322206131n.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200120000931.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20180203222921-dadab393fb38472558f8bebc58a6006c-tablet.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path cba5afe7-67d8-48a4-ad60-d1d21948c393_size190_w1024_h795.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 7399e9d37dcd470282ebd4b86f52d342.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path Coronavirus-1024x683.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20180227002525.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3061836_4_1.jpg\n",
            " 3/78 [>.............................] - ETA: 36:21 - loss: 120926.3854self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1510128306-781.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 15150794626913.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200122a220554.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path image2.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path A-group-of-students-wearing-protective-masks-walk-outside-a-railway-station-amid-coronavirus-fears-in-Kochi-India-March-10-2020-Reuters-770x433.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path BBZppaq.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path afe056da-d40d-11e7-93d7-6d6fc14be448_1280x720_155100.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 002_1024.jpeg\n",
            " 4/78 [>.............................] - ETA: 35:52 - loss: 117326.4492self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20180927232308_67563e2a7ebff07ad2d2cf1d606fc2a3_4.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 0200b38c89b16c37c5de8e247bb00c2f.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path Coronavirus-Mumbai-1-1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path GettyImages-1197620885.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path how-to-wear-surgical-masks-3-768x1024.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path detectan_nuevos_casos_de_neumonia_virica_en_china.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 89da4fbbd90bc2b2365f221705284446.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3414e5ff97f342dd803e048c4670b8ac.jpg\n",
            " 5/78 [>.............................] - ETA: 35:40 - loss: 113303.2750self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 9a9290ce-013c-4792-9fb7-183ef7326ab5e5743997-df54-41f6-b994-d779c59ccb8e_batchwm_batchwm.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1303078448-China-Coronavirus-Death-Toll-Hits-304.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path images13.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 23861842-7929865-A_rotation_team_of_seven_doctors_are_stationed_at_Heathrow_passe-a-16_1579992713145.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path a-lady-wears-a-mask-while-visiting-tiananmen-square-in-beijing-february-DWC228.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 520ba294-d9d3-11e9-80eb-3aa57b6d2433_image_hires_212554.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-china-gty-aa-200124_hpMain_16x9_992.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-philippines.jpg\n",
            " 6/78 [=>............................] - ETA: 34:58 - loss: 109177.2904self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 420x0.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 040420-cc-ap-facemask-public-img.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 8b74444760f670bb5cee48f86bb7be950bf113a8.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1_13.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path https___cdn.cnn.com_cnnnext_dam_assets_200122173230-01222020-wuhan-virus-visual-guide---page-top.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 26_09_2019-air-pollution-chidrens_19614664.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path asian-girl-wearing-a-dust-mask-pm25-on-bed-health-care-concept-T6BBWK.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e305d2724306a4b381e8ea3.jpeg\n",
            " 7/78 [=>............................] - ETA: 34:21 - loss: 105144.7511self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-4.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 0_Concern-In-China-As-Mystery-Virus-Spreads.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 01_10_2019-anti_pollution_mask_19630124_134638416158337925648415859824102601586357139630.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e2754d1bd621.image.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020_0120_7f239fc9j00q4e1uf001mc000xc00irc.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e2ac9654bbdd_o_full.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e311c9d2f7f7.image.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path _111550872_gettyimages-1128162568.jpg\n",
            " 8/78 [==>...........................] - ETA: 33:47 - loss: 101295.1455self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 22d58fb1b9fff9d408d36a2c2313b217.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path asian-child-wearing-mask-prevent-protection-factor-for-n95-filtering-face-mask-safty-white-mask-T5WP83.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1024x737_09186876046.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 19970010p890r390q90o.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path china-coronavirus-beijing-station-spring-festival.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20371517_web1_200131-RDA-New-coronavirus-has-now-infected-almost-10000-including-three-in-Canada-coronavirus_1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path fj44ruyrt.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 46db30ff1d5a845cbe4e481ccc2626cd-149819.jpg\n",
            " 9/78 [==>...........................] - ETA: 33:17 - loss: 97666.7734 self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 012420_coronoa_masks_web.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path febfe125a0904416a97b9ff3be08517c.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path images18.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path abstrax_art_13120-copy.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200123123851-6c35b988.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3060869_1_1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path GettyImages-1195102180-1_1200x1200.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-bengaluru-pti160320.jpg\n",
            "10/78 [==>...........................] - ETA: 32:46 - loss: 94260.9141self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20190919FL13.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200206132610-95105bc6.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-chinois-est-encore-trop-tot-pour-parler-pandemie.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path AAIRPORT12_oic_pic.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 960x00.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path ca_coronaviruscontagious_012720getty.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-lockdown-delhi-pti200420.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1029731146.jpg\n",
            "11/78 [===>..........................] - ETA: 32:16 - loss: 91077.9023self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020_01_25_85193_1579923621._large.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path CHINA_OUTBREAK_57865119JPG.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 200210163309-coronavirus-economia-mundial-afecta-brote-virus-portafolio-global-cnnee-00000000.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20190110210654_50.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path f-chinasmog-a-20150223-870x605.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path bangkok-thailand-9th-feb-2018-people-wear-face-masks-to-protect-themselves-M34T39.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-iran-test-positive-india-1585651948.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path images9.jpg\n",
            "12/78 [===>..........................] - ETA: 31:44 - loss: 88098.6172self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 15391513321824spp815on8.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path file-20200404-74255-1jr55gc.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20170804_20170804-150134.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020_4largeimg_1457131882.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 0009S6815V3PEU1N-C123-F4.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3513124.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200129001153.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200201002898.jpg\n",
            "13/78 [====>.........................] - ETA: 31:13 - loss: 85307.6599self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path Coronavirus_EPS_4.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path epidemie_coronavirus_2019_ncov_chine.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 765007-china-battles-coronavirus-outbreak-all-the-latest-updates.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5e26f95fa3101282064d4b72.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 0602623232127-web-tete.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path hong-kong-face-masks-ban_wide-99cdd7414e7eccf0eddeeb3f1ab7b63dad878f11.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path image5.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path des-banlieusards-portant-des-masques-font-la-queue-a-la-gare-de-wuchang-a-wuhan-dans-la-province-centrale-du-hubei-en-chine-le-22-janvier-2020_6246102.jpg\n",
            "14/78 [====>.........................] - ETA: 30:44 - loss: 82692.1970self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path chine-virus-.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 0209-00176-076b1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path air-pollution-delhi_2045672_835x547-m.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path CHINA-VIRUS-TRAVEL-1-SOC.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3050308_1_1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20171111234800_96.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 23012020_VirusMacau(cover)_AFP.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 004_1024.jpeg\n",
            "15/78 [====>.........................] - ETA: 30:13 - loss: 80239.3211self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 53257032_401.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200129151820_fd638cb7a2000a1096ca3fbdc15a6fa9_1.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5949e78f384b4.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path image10.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020-02-11t080104z_642105741_rc28ye91qg4c_rtrmadp_3_china-health.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path EI5OJLAMAFFI5M3G3ZU2ISJCL4.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 843b3ea7c0eb9b80617cdac8d95afc0e.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1539151332674193npsrq70.jpg\n",
            "16/78 [=====>........................] - ETA: 29:44 - loss: 77936.1367self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path ckeditor-5e45049792adb.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 380ba2c750bacbf52432089e87796264.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 5sf7bryou3oyhngo_1589206751.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path aad5d6ef-413e-4aa3-8e02-12d9178c5489.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path https___cdn.cnn.com_cnnnext_dam_assets_200201102936-wuhan-virus-0131-beijing-masks.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 190327-05_1024.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path article-2100912-11BB7D10000005DC-415_634x402.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path Coronavirus-6-1024x576.jpg\n",
            "17/78 [=====>........................] - ETA: 29:15 - loss: 75769.0738self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200129001040.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 11973151840.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path e68891e4bbace69c89e782b9e4b88de5ae89efbc9ae586a0e78ab6e79785e6af92e6a188e58f91e7949fe5908eefbc8ce7baa6e5858be5ada6e7949f.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path Cotton-PM2-5-Black-mouth-Mask-anti-dust-mask-Activated-carbon-filter-Windproof-Mouth-muffle.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3056453_1_1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 9125fe343fe5b1208c8b44e46df02ad4output_00002.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path BBZdb0i.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path China-coronavirus-9.jpg\n",
            "18/78 [=====>........................] - ETA: 28:45 - loss: 73728.4974self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path images17.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path coronavirus-outbreak-china-japan-ap.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path c1_1844849.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020012921402900_1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path da31b29a47d66e142b45e39eadf68b49.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1580173904-0001oc33f.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path group-of-people-waiting-at-a-bus-shelter-in-bethnal-green-london-C1K7ME.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 11893820-3x2-xlarge.jpg\n",
            "19/78 [======>.......................] - ETA: 28:16 - loss: 71805.8273self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 3FED259000000578-4472558-Dangerous_People_in_northern_China_were_seen_wearing_masks_and_c-a-2_1493888420858.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path airport-mask-1200x830.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path D929_44_634_1200.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path d3144235.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path airport-facemask.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20200206102815-d6a8099999dddcaf74281ddf55e12856-mobile.jpeg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2019040317133725925.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1581171518_471_The-video-shows-officials-in-protective-suits-dragging-suspected-coronavirus.jpg\n",
            "20/78 [======>.......................] - ETA: 27:47 - loss: 69991.6707self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 200226-mask-al-1000_44f587f4c07bff8c80b10a8c0b6b2219.fit-760w.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 2020-01-31t145112z-316030556-mt1yomiur000ajsyux-rtrmadp-3-novel-coronavirus-outbreak-japan-tokyo-1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 4673875.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 20181204072707536.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path cff8244482ede545b1d81c9be7f5b6ed_original.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path D237_57_812_1200.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path busstop-1.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 12077936-3x2-940x627.jpg\n",
            "21/78 [=======>......................] - ETA: 27:17 - loss: 68276.0623self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 1580254255-c2913345cf530d48618522071d23e606.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path article-5e450331d87b6.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path gettyimages-491638349-1024x1024.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path B02A00_P_04_02.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path edinburgh.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 6000x4000_859864610306.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path corona759.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 8b13ac10-40d7-11ea-bbf7-2b13a42548bc.jpg\n",
            "22/78 [=======>......................] - ETA: 26:48 - loss: 66651.9905self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path 025418_springwest005.jpg\n",
            "self.folder_path /content/drive/My Drive/Colab Notebooks/images-20210217T050756Z-001/images/train_images_test/\n",
            "img_path CHINA-HEALTH-VIRUS-134752\n",
            "23/78 [=======>......................] - ETA: 26:19 - loss: 65111.9522"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a3f6e99566b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mval_data_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_gen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           callbacks=[model_cp,reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/yolo-v4-tf.keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data_gen, epochs, val_data_gen, initial_epoch, callbacks)\u001b[0m\n\u001b[1;32m    105\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;31m# raw_img: RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  TypeError: 'NoneType' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"../utils.py\", line 159, in __getitem__\n    X, y_tensor, y_bbox = self.__data_generation(lines)\n\n  File \"../utils.py\", line 179, in __data_generation\n    img_data, box_data = self.get_data(line)\n\n  File \"../utils.py\", line 193, in get_data\n    img = cv2.imread(os.path.join(self.folder_path, img_path))[:, :, ::-1]\n\nTypeError: 'NoneType' object is not subscriptable\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_31345]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkP21Yb--d8X"
      },
      "source": [
        "os.chdir('images-20210217T050756Z-001/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3KaGe0T9CTD",
        "outputId": "2220d4d6-cced-4f4f-cda8-d220b384caa0"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of data_on_all_incidents.ipynb'\n",
            "'Copy of Lstm_Attention_textclassification.ipynb'\n",
            "'Copy of mmw_cnn1d_colab.ipynb'\n",
            "'Copy of Snippets: Importing libraries'\n",
            "'Copy of Untitled1.ipynb'\n",
            "'Copy of with_mix_2018_data (1).ipynb'\n",
            "'Copy of with_mix_2018_data.ipynb'\n",
            " data_on_all_incidents.ipynb\n",
            "'facing_problem_loding_lstm _attention.ipynb'\n",
            " geanie\n",
            " Glove_with_mix_2018_data.ipynb\n",
            " images-20210217T050756Z-001\n",
            " Itera_3_with_mix_2018_data.ipynb\n",
            " Lstm_Attention_textclassification.ipynb\n",
            " Lstm_Attention_textclassification_nehru.ipynb\n",
            " Mean_W2VEC_with_mix_2018_data.ipynb\n",
            " mmw_cnn1d_colab.ipynb\n",
            " processed_images.zip\n",
            " test_on_data_on_all_incidents.ipynb\n",
            " TFIDF_W2VEC_with_mix_2018_data.ipynb\n",
            " TF_object_detection.ipynb\n",
            " Top_cis_gt_1000.ipynb\n",
            " Top_cis_lt_1000.ipynb\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            " Untitled4.ipynb\n",
            " Untitled5.ipynb\n",
            " Untitled6.ipynb\n",
            " util1.ipynb\n",
            " yolo-v4-tf.keras\n",
            " yolo-v4-tf.keras.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDsEUHWi9CV4",
        "outputId": "d3718391-21a0-4032-f592-9911094e8433"
      },
      "source": [
        "! unzip processed_images.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  processed_images.zip\n",
            "replace images-20210217T050756Z-001/images/classes.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}